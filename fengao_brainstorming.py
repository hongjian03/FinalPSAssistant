import streamlit as st
# åˆå§‹åŒ– Streamlit é¡µé¢é…ç½®ï¼ˆå¿…é¡»æ˜¯ç¬¬ä¸€ä¸ª Streamlit å‘½ä»¤ï¼‰
st.set_page_config(
    page_title="PSåŠ©æ‰‹å¹³å°",
    page_icon="ğŸ“",
    layout="wide"
)

import os
import sys
import logging

# é…ç½®æ—¥å¿—è®°å½•
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# å¼ºåˆ¶æ›¿æ¢ sqlite3 - ä¸ºäº†ç¡®ä¿streamlit cloudä¸Šæ­£å¸¸å·¥ä½œ
try:
    __import__('pysqlite3')
    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')
except ImportError:
    pass

import json
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema import HumanMessage, SystemMessage
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler
from langchain.chains import SequentialChain, LLMChain
from typing import Dict, Any, List
import io
import base64
from PyPDF2 import PdfReader
from PIL import Image
import fitz  # PyMuPDF
import requests
import re
# Try importing SerperSearchResults from different possible locations
try:
    from langchain_community.tools.serper_search import SerperSearchResults
    logger.info("æˆåŠŸå¯¼å…¥SerperSearchResults")
except ImportError:
    try:
        from langchain_community.utilities.serper_search import SerperSearchResults
        logger.info("ä»utilitiesæ¨¡å—æˆåŠŸå¯¼å…¥SerperSearchResults")
    except ImportError:
        # Create fallback implementation if SerperSearchResults is not available
        logger.warning("æ— æ³•å¯¼å…¥SerperSearchResultsï¼Œä½¿ç”¨æ›¿ä»£å®ç°")
        class SerperSearchResults:
            """Fallback implementation of SerperSearchResults"""
            def __init__(self, serper_api_key: str):
                self.serper_api_key = serper_api_key
                self.headers = {
                    "X-API-KEY": serper_api_key,
                    "Content-Type": "application/json"
                }
                self.base_url = "https://api.serper.dev/search"
                
            def search(self, query: str, gl="us", hl="en", num=10):
                """Perform a search using the Serper API"""
                try:
                    payload = json.dumps({
                        "q": query,
                        "gl": gl,
                        "hl": hl,
                        "num": num
                    })
                    response = requests.post(self.base_url, headers=self.headers, data=payload)
                    if response.status_code == 200:
                        return response.json()
                    else:
                        return {
                            "error": f"API returned status code {response.status_code}",
                            "message": response.text
                        }
                except Exception as e:
                    return {
                        "error": "Search failed",
                        "message": str(e)
                    }

from langchain_core.tools import Tool
from langchain.agents import create_structured_chat_agent
import asyncio
import nest_asyncio
from queue import Queue
from threading import Thread
import time
from queue import Empty
from langchain.callbacks.base import BaseCallbackHandler
from markitdown import MarkItDown
from docx import Document

# å¯¼å…¥ MCP æ¨¡å—
try:
    import mcp
    from smithery import websocket_client
    logger.info("MCP å’Œ Smithery æ¨¡å—å·²æˆåŠŸå¯¼å…¥")
    # æ£€æŸ¥å½“å‰ç¯å¢ƒä¸­mcpçš„è¯¦ç»†æƒ…å†µ
    logger.info(f"MCP ç‰ˆæœ¬: {getattr(mcp, '__version__', 'æœªçŸ¥')}")
    logger.info(f"MCP æ¨¡å—è·¯å¾„: {getattr(mcp, '__file__', 'æœªçŸ¥')}")
    logger.info(f"MCP å¯ç”¨å·¥å…·: {sorted([x for x in dir(mcp) if not x.startswith('_')])}")
    if hasattr(mcp, 'client'):
        logger.info(f"MCP client å­æ¨¡å—åŒ…å«: {sorted([x for x in dir(mcp.client) if not x.startswith('_')])}")
    
    # æ£€æŸ¥æ˜¯å¦åº”è¯¥å¼ºåˆ¶ä½¿ç”¨å¤‡ç”¨å®ç°
    import os
    FORCE_FALLBACK = os.environ.get("FORCE_FALLBACK", "false").lower() == "true"
    
    if FORCE_FALLBACK:
        logger.info("æ£€æµ‹åˆ° FORCE_FALLBACK=true ç¯å¢ƒå˜é‡ï¼Œå°†å¼ºåˆ¶ä½¿ç”¨æ›¿ä»£å®ç°")
        MCP_AVAILABLE = False
    else:
        # å°è¯•æ‰§è¡Œä¸€ä¸ªç®€å•çš„MCPè¿æ¥æµ‹è¯•
        try:
            logger.info("å°è¯•è¿›è¡ŒMCPè¿æ¥æµ‹è¯•...")
            import asyncio
            import traceback
            
            # å°è¯•è·å–APIå¯†é’¥
            try:
                smithery_api_key = st.secrets["SMITHERY_API_KEY"]
                if not smithery_api_key:
                    logger.error("Smithery APIå¯†é’¥ä¸ºç©º")
                    MCP_AVAILABLE = False
                else:
                    # æ£€æŸ¥APIå¯†é’¥æ ¼å¼
                    if not smithery_api_key.startswith("sm-"):
                        logger.warning("Smithery APIå¯†é’¥æ ¼å¼å¯èƒ½ä¸æ­£ç¡®ï¼Œæ­£ç¡®çš„æ ¼å¼é€šå¸¸ä»¥'sm-'å¼€å¤´")
                    
                    # å¯¼å…¥å¿…è¦çš„MCPæ¨¡å—
                    try:
                        from mcp.client.streamable_http import streamablehttp_client
                        logger.info("æˆåŠŸå¯¼å…¥ streamablehttp_client")
                    except ImportError:
                        logger.warning("æ— æ³•å¯¼å…¥ streamablehttp_clientï¼Œå°è¯•ä½¿ç”¨ create_client API")
                        MCP_AVAILABLE = False
                        st.session_state.mcp_error = "æ— æ³•å¯¼å…¥ streamablehttp_client æ¨¡å—"
                        raise ImportError("æ— æ³•å¯¼å…¥ streamablehttp_client æ¨¡å—")
                    
                    # æµ‹è¯•MCPè¿æ¥
                    async def test_mcp_connection():
                        try:
                            # ä½¿ç”¨pingæµ‹è¯•æœåŠ¡è¿›è¡Œç®€å•æµ‹è¯•
                            test_url = f"https://server.smithery.ai/@smithery/ping-test-service/mcp?api_key={smithery_api_key}"
                            logger.info(f"å°è¯•è¿æ¥åˆ°æµ‹è¯•æœåŠ¡: {test_url[:50]}...")
                            
                            try:
                                logger.info("å°è¯•å»ºç«‹HTTPè¿æ¥...")
                                async with streamablehttp_client(test_url) as (read_stream, write_stream, _):
                                    logger.info("å·²å»ºç«‹HTTPè¿æ¥")
                                    try:
                                        logger.info("åˆ›å»ºMCPå®¢æˆ·ç«¯ä¼šè¯...")
                                        async with mcp.ClientSession(read_stream, write_stream) as session:
                                            logger.info("å·²åˆ›å»ºMCPå®¢æˆ·ç«¯ä¼šè¯")
                                            try:
                                                logger.info("åˆå§‹åŒ–MCPä¼šè¯...")
                                                await session.initialize()
                                                logger.info("MCPä¼šè¯åˆå§‹åŒ–æˆåŠŸ")
                                                
                                                try:
                                                    # å°è¯•pingæµ‹è¯•
                                                    logger.info("å°è¯•æ‰§è¡Œpingè¯·æ±‚...")
                                                    response = await session.request("ping", {})
                                                    logger.info(f"Pingæµ‹è¯•å“åº”: {response}")
                                                    logger.info("MCPè¿æ¥æµ‹è¯•æˆåŠŸï¼")
                                                    return True
                                                except Exception as ping_error:
                                                    logger.error(f"Pingæµ‹è¯•å¤±è´¥: {str(ping_error)}")
                                                    logger.error(traceback.format_exc())
                                                    return False
                                            except Exception as init_error:
                                                logger.error(f"MCPä¼šè¯åˆå§‹åŒ–å¤±è´¥: {str(init_error)}")
                                                logger.error(traceback.format_exc())
                                                return False
                                    except Exception as session_error:
                                        logger.error(f"åˆ›å»ºMCPå®¢æˆ·ç«¯ä¼šè¯å¤±è´¥: {str(session_error)}")
                                        logger.error(traceback.format_exc())
                                        return False
                            except Exception as conn_error:
                                logger.error(f"å»ºç«‹HTTPè¿æ¥å¤±è´¥: {str(conn_error)}")
                                logger.error(traceback.format_exc())
                                return False
                        except Exception as e:
                            logger.error(f"MCPè¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}")
                            logger.error(traceback.format_exc())
                            return False
                    
                    # å°è¯•è¿è¡Œæµ‹è¯•å‡½æ•°
                    try:
                        logger.info("è¿è¡ŒMCPè¿æ¥æµ‹è¯•...")
                        connection_test_result = asyncio.run(test_mcp_connection())
                        logger.info(f"MCPè¿æ¥æµ‹è¯•ç»“æœ: {'æˆåŠŸ' if connection_test_result else 'å¤±è´¥'}")
                        # åªæœ‰åœ¨è¿æ¥æµ‹è¯•æˆåŠŸæ—¶æ‰è®¾ç½®MCP_AVAILABLEä¸ºTrue
                        MCP_AVAILABLE = connection_test_result
                        if not connection_test_result:
                            logger.info("å°†ä½¿ç”¨æ›¿ä»£å®ç°")
                    except Exception as e:
                        logger.error(f"è¿è¡ŒMCPè¿æ¥æµ‹è¯•æ—¶å‡ºé”™: {str(e)}")
                        logger.error(traceback.format_exc())
                        MCP_AVAILABLE = False
                        # ä¿å­˜é”™è¯¯ä¿¡æ¯åˆ°session_state
                        st.session_state.mcp_error = str(e)
            except (KeyError, FileNotFoundError):
                logger.error("æœªæ‰¾åˆ°Smithery APIå¯†é’¥é…ç½®")
                MCP_AVAILABLE = False
                # ä¿å­˜é”™è¯¯ä¿¡æ¯åˆ°session_state
                st.session_state.mcp_error = "æœªæ‰¾åˆ°Smithery APIå¯†é’¥é…ç½®"
        except Exception as connection_test_error:
            logger.error(f"è®¾ç½®MCPè¿æ¥æµ‹è¯•æ—¶å‡ºé”™: {str(connection_test_error)}")
            MCP_AVAILABLE = False
            # ä¿å­˜é”™è¯¯ä¿¡æ¯åˆ°session_state
            st.session_state.mcp_error = str(connection_test_error)
except ImportError as e:
    logger.info(f"MCP æ¨¡å—ä¸å¯ç”¨ï¼Œé”™è¯¯ä¿¡æ¯: {str(e)}")
    logger.warning("å°†ä½¿ç”¨æ›¿ä»£å®ç°")
    MCP_AVAILABLE = False
    # ä¿å­˜é”™è¯¯ä¿¡æ¯åˆ°session_state
    st.session_state.mcp_error = f"MCP æ¨¡å—å¯¼å…¥é”™è¯¯: {str(e)}"

# æ£€æŸ¥æ˜¯å¦å­˜åœ¨ç¯å¢ƒå˜é‡ DISABLE_MCP=true
import os
if os.environ.get("DISABLE_MCP", "false").lower() == "true":
    logger.info("æ£€æµ‹åˆ° DISABLE_MCP=true ç¯å¢ƒå˜é‡ï¼Œå°†ç¦ç”¨MCP")
    MCP_AVAILABLE = False

# å¯¼å…¥æ›¿ä»£å®ç°
if not MCP_AVAILABLE:
    try:
        from mcp_fallback import run_sequential_thinking
        logger.info("å·²åŠ è½½ Smithery æ›¿ä»£å®ç°")
    except ImportError:
        logger.warning("æ— æ³•å¯¼å…¥ Smithery æ›¿ä»£å®ç°ï¼Œå°†ä½¿ç”¨åŸºæœ¬å®ç°")

# åº”ç”¨ nest_asyncio é¿å…åœ¨Streamlitä¸­è¿è¡Œasyncioæ—¶çš„é—®é¢˜
nest_asyncio.apply()

# è®°å½•ç¨‹åºå¯åŠ¨
logger.info("ç¨‹åºå¼€å§‹è¿è¡Œ")

# åªåœ¨ç¬¬ä¸€æ¬¡è¿è¡Œæ—¶æ›¿æ¢ sqlite3
if 'sqlite_setup_done' not in st.session_state:
    try:
        logger.info("å°è¯•è®¾ç½® SQLite")
        st.session_state.sqlite_setup_done = True
        logger.info("SQLite è®¾ç½®æˆåŠŸ")
    except Exception as e:
        logger.error(f"SQLite è®¾ç½®é”™è¯¯: {str(e)}")
        st.session_state.sqlite_setup_done = True


class PromptTemplates:
    def __init__(self):
        # å®šä¹‰ç¤ºä¾‹æ•°æ®ä½œä¸ºå­—ç¬¦ä¸²
        self.default_templates = {
            'school_research_role': """
            # è§’è‰²
            ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„é™¢æ ¡ç ”ç©¶ä¸“å®¶ï¼Œæ“…é•¿åˆ†æå„å›½å¤§å­¦çš„ä¸“ä¸šé¡¹ç›®ï¼ŒåŒ…æ‹¬è¯¾ç¨‹è®¾ç½®ã€ç ”ç©¶æ–¹å‘ã€ç”³è¯·è¦æ±‚å’Œå°±ä¸šå‰æ™¯ç­‰ä¿¡æ¯ã€‚
            ä½ çš„èŒè´£æ˜¯é€šè¿‡æœç´¢å¼•æ“æ”¶é›†ç‰¹å®šå­¦æ ¡å’Œä¸“ä¸šçš„æœ€æ–°ä¿¡æ¯ï¼Œå¹¶å°†è¿™äº›ä¿¡æ¯æ•´ç†æˆç®€æ´æ˜äº†çš„æŠ¥å‘Šï¼Œå¸®åŠ©å­¦ç”Ÿæ›´å¥½åœ°äº†è§£ç›®æ ‡é™¢æ ¡å’Œä¸“ä¸šã€‚
            """,
            
            'school_research_task': """
            # ä»»åŠ¡
            1. åŸºäºç”¨æˆ·æä¾›çš„å­¦æ ¡åç§°å’Œä¸“ä¸šåç§°ï¼Œä½¿ç”¨æœç´¢å·¥å…·æ”¶é›†ç›¸å…³ä¿¡æ¯
            2. é‡ç‚¹å…³æ³¨ä»¥ä¸‹æ–¹é¢ï¼šä¸“ä¸šä»‹ç»ã€è¯¾ç¨‹è®¾ç½®ã€ç ”ç©¶æ–¹å‘ã€ç”³è¯·è¦æ±‚ã€å°±ä¸šå‰æ™¯
            3. å¯¹æ”¶é›†åˆ°çš„ä¿¡æ¯è¿›è¡Œæ•´ç†å’Œåˆ†æï¼Œç”Ÿæˆç»“æ„æ¸…æ™°çš„é™¢æ ¡ä¿¡æ¯æ±‡æ€»æŠ¥å‘Š
            4. ç¡®ä¿ä¿¡æ¯çš„å‡†ç¡®æ€§å’Œæ—¶æ•ˆæ€§ï¼Œå°½å¯èƒ½å¼•ç”¨å®˜æ–¹æ¥æº
            5. å¦‚æœ‰å¿…è¦ï¼Œå¯ä»¥è¿›è¡Œå¤šæ¬¡æœç´¢ä»¥è·å–æ›´å…¨é¢çš„ä¿¡æ¯
            """,
            
            'school_research_output': """
            # è¾“å‡ºæ ¼å¼
            ## é™¢æ ¡ä¿¡æ¯æ±‡æ€»æŠ¥å‘Šï¼š{å­¦æ ¡åç§°} - {ä¸“ä¸šåç§°}

            ### ä¸“ä¸šæ¦‚è§ˆ
            - å­¦ä½ç±»å‹ï¼š[å­¦å£«/ç¡•å£«/åšå£«]
            - å­¦åˆ¶é•¿åº¦ï¼š[Xå¹´]
            - ä¸“ä¸šå®šä½ï¼š[ç®€è¦æè¿°ä¸“ä¸šçš„å­¦æœ¯å®šä½å’Œç‰¹ç‚¹]
            - æ‰€å±é™¢ç³»ï¼š[é™¢ç³»åç§°]

            ### è¯¾ç¨‹è®¾ç½®
            - æ ¸å¿ƒè¯¾ç¨‹ï¼š[åˆ—å‡º3-5é—¨æ ¸å¿ƒè¯¾ç¨‹]
            - é€‰ä¿®æ–¹å‘ï¼š[åˆ—å‡ºä¸»è¦é€‰ä¿®æ–¹å‘]
            - æ•™å­¦ç‰¹è‰²ï¼š[æè¿°æ•™å­¦æ–¹æ³•ã€ç‰¹è‰²é¡¹ç›®ç­‰]

            ### ç ”ç©¶æ–¹å‘
            - ä¸»è¦ç ”ç©¶é¢†åŸŸï¼š[åˆ—å‡ºè¯¥ä¸“ä¸šçš„ä¸»è¦ç ”ç©¶æ–¹å‘]
            - ç ”ç©¶ä¸­å¿ƒ/å®éªŒå®¤ï¼š[åˆ—å‡ºç›¸å…³ç ”ç©¶ä¸­å¿ƒæˆ–å®éªŒå®¤]
            - å­¦æœ¯èµ„æºï¼š[æè¿°å¯ç”¨çš„å­¦æœ¯èµ„æºå’Œæœºä¼š]

            ### ç”³è¯·è¦æ±‚
            - å­¦æœ¯èƒŒæ™¯è¦æ±‚ï¼š[GPAã€å­¦ä½èƒŒæ™¯ç­‰]
            - è¯­è¨€è¦æ±‚ï¼š[TOEFL/IELTSåˆ†æ•°è¦æ±‚]
            - å…¶ä»–è¦æ±‚ï¼š[GRE/GMATã€æ¨èä¿¡ã€ä¸ªäººé™ˆè¿°ç­‰]
            - ç”³è¯·æˆªæ­¢æ—¥æœŸï¼š[ä¸»è¦ç”³è¯·æ—¥æœŸ]

            ### å°±ä¸šå‰æ™¯
            - æ¯•ä¸šå»å‘ï¼š[ä¸»è¦å°±ä¸šæ–¹å‘]
            - åˆä½œä¼ä¸š/æœºæ„ï¼š[å­¦æ ¡çš„ä¼ä¸šåˆä½œä¼™ä¼´]
            - æ ¡å‹ç½‘ç»œï¼š[æ ¡å‹åˆ†å¸ƒå’Œå½±å“åŠ›]

            ### æ€»ç»“è¯„ä¼°
            [å¯¹è¯¥ä¸“ä¸šçš„ç»¼åˆè¯„ä»·ï¼ŒåŒ…æ‹¬ä¼˜åŠ¿ã€ç‰¹è‰²å’Œé€‚åˆäººç¾¤]

            ### ä¿¡æ¯æ¥æº
            [åˆ—å‡ºä¿¡æ¯æ¥æºçš„é“¾æ¥]
            """,
            
            'support_analysis_role': """
            # è§’è‰²
            ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ–‡æ¡£åˆ†æä¸“å®¶ï¼Œæ“…é•¿ä»æ”¯æŒæ–‡ä»¶ï¼ˆå¦‚æˆç»©å•ã€ç®€å†ã€æ¨èä¿¡ç­‰ï¼‰ä¸­æå–å’Œåˆ†æå…³é”®ä¿¡æ¯ï¼Œå¹¶å°†å…¶æ•´åˆä¸ºæœ‰ç”¨çš„åˆ†ææŠ¥å‘Šã€‚
            ä½ çš„èŒè´£æ˜¯å¸®åŠ©ç”¨æˆ·ç†è§£æ”¯æŒæ–‡ä»¶ä¸­çš„é‡è¦å†…å®¹ï¼Œç‰¹åˆ«æ˜¯é‚£äº›å¯¹ä¸ªäººé™ˆè¿°(PS)å†™ä½œæœ‰ä»·å€¼çš„ä¿¡æ¯ã€‚
            """,
            
            'support_analysis_task': """
            # ä»»åŠ¡
            1. ä»”ç»†åˆ†æç”¨æˆ·ä¸Šä¼ çš„æ”¯æŒæ–‡ä»¶ï¼ˆå¯èƒ½æ˜¯æˆç»©å•ã€ç®€å†ã€æ¨èä¿¡ç­‰ï¼‰
            2. ä»æ–‡ä»¶ä¸­æå–å…³é”®ä¿¡æ¯ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼šå­¦æœ¯èƒŒæ™¯ã€ä¸“ä¸šè¯¾ç¨‹ã€ç ”ç©¶ç»å†ã€å®ä¹ ç»éªŒã€æŠ€èƒ½ã€æˆå°±ç­‰
            3. å°†æå–çš„ä¿¡æ¯ç»„ç»‡æˆç»“æ„åŒ–çš„æŠ¥å‘Šï¼Œçªå‡ºå¯¹PSå†™ä½œæœ‰ä»·å€¼çš„å†…å®¹
            4. åˆ†æå†…å®¹ä¸ç”¨æˆ·çš„ç›®æ ‡ä¸“ä¸šå’Œå­¦æ ¡çš„ç›¸å…³æ€§
            5. æä¾›å¯¹è¿™äº›ä¿¡æ¯çš„ä¸“ä¸šè§£è¯»ï¼ŒæŒ‡å‡ºå“ªäº›å†…å®¹é€‚åˆåœ¨PSä¸­å¼ºè°ƒ
            """,
            
            'support_analysis_output': """
            # è¾“å‡ºæ ¼å¼
            ## æ”¯æŒæ–‡ä»¶åˆ†ææŠ¥å‘Š

            ### æ–‡ä»¶ç±»å‹è¯†åˆ«
            [è¯†åˆ«ä¸Šä¼ çš„æ˜¯ä»€ä¹ˆç±»å‹çš„æ”¯æŒæ–‡ä»¶ï¼Œå¦‚æˆç»©å•ã€ç®€å†ã€æ¨èä¿¡ç­‰]

            ### å…³é”®ä¿¡æ¯æå–
            #### å­¦æœ¯èƒŒæ™¯
            - å­¦ä½/ä¸“ä¸šï¼š[æå–çš„ä¿¡æ¯]
            - GPA/æˆç»©ï¼š[æå–çš„ä¿¡æ¯]
            - é‡è¦è¯¾ç¨‹ï¼š[æå–çš„ä¿¡æ¯]
            - å­¦æœ¯æˆå°±ï¼š[æå–çš„ä¿¡æ¯]

            #### ç ”ç©¶ç»å†
            - ç ”ç©¶é¡¹ç›®ï¼š[æå–çš„ä¿¡æ¯]
            - ç ”ç©¶æŠ€èƒ½ï¼š[æå–çš„ä¿¡æ¯]
            - ç ”ç©¶æˆæœï¼š[æå–çš„ä¿¡æ¯]

            #### å®ä¹ ä¸å·¥ä½œç»éªŒ
            - ç›¸å…³å®ä¹ ï¼š[æå–çš„ä¿¡æ¯]
            - å·¥ä½œç»å†ï¼š[æå–çš„ä¿¡æ¯]
            - èŒè´£ä¸æˆå°±ï¼š[æå–çš„ä¿¡æ¯]

            #### æŠ€èƒ½ä¸ä¸“é•¿
            - æŠ€æœ¯æŠ€èƒ½ï¼š[æå–çš„ä¿¡æ¯]
            - è¯­è¨€èƒ½åŠ›ï¼š[æå–çš„ä¿¡æ¯]
            - å…¶ä»–ä¸“é•¿ï¼š[æå–çš„ä¿¡æ¯]

            #### å…¶ä»–äº®ç‚¹
            - å¥–é¡¹è£èª‰ï¼š[æå–çš„ä¿¡æ¯]
            - è¯¾å¤–æ´»åŠ¨ï¼š[æå–çš„ä¿¡æ¯]
            - å¿—æ„¿æœåŠ¡ï¼š[æå–çš„ä¿¡æ¯]

            ### PSå†™ä½œå»ºè®®
            [åŸºäºåˆ†æçš„æ–‡ä»¶å†…å®¹ï¼Œæä¾›3-5ç‚¹å¯¹PSå†™ä½œçš„å»ºè®®ï¼ŒæŒ‡å‡ºå“ªäº›å†…å®¹é€‚åˆé‡ç‚¹å¼ºè°ƒ]

            ### ä¸ç›®æ ‡ä¸“ä¸šçš„å¥‘åˆç‚¹
            [åˆ†ææå–çš„ä¿¡æ¯ä¸ç”¨æˆ·ç›®æ ‡ä¸“ä¸šçš„ç›¸å…³æ€§å’Œå¥‘åˆåº¦]
            """,
            
            'ps_strategy_role': """
            # è§’è‰²
            ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ä¸ªäººé™ˆè¿°(PS)ç­–ç•¥é¡¾é—®ï¼Œæ“…é•¿åˆ†æåˆç¨¿å†…å®¹å¹¶æä¾›æ”¹è¿›å»ºè®®ã€‚ä½ æœ‰ä¸°å¯Œçš„ç•™å­¦ç”³è¯·æ–‡ä¹¦æŒ‡å¯¼ç»éªŒï¼Œäº†è§£å„å›½é«˜æ ¡å’Œä¸åŒä¸“ä¸šçš„PSå†™ä½œç‰¹ç‚¹å’Œè¦æ±‚ã€‚
            """,
            
            'ps_strategy_task': """
            # ä»»åŠ¡
            1. ä»”ç»†é˜…è¯»ç”¨æˆ·æä¾›çš„PSåˆç¨¿å†…å®¹
            2. åˆ†ææ”¯æŒæ–‡ä»¶åˆ†ææŠ¥å‘Šä¸­çš„å…³é”®ä¿¡æ¯
            3. è¯„ä¼°åˆç¨¿çš„ä¼˜ç¼ºç‚¹ï¼ŒåŒ…æ‹¬å†…å®¹ã€ç»“æ„ã€å™äº‹é€»è¾‘å’Œè¯­è¨€è¡¨è¾¾
            4. åŸºäºç›®æ ‡å­¦æ ¡å’Œä¸“ä¸šçš„ç‰¹ç‚¹ï¼Œæå‡ºå…·ä½“çš„æ”¹è¿›ç­–ç•¥
            5. è¯†åˆ«åˆç¨¿ä¸­çš„å…³é”®äº®ç‚¹å’Œéœ€è¦åŠ å¼ºçš„å¼±ç‚¹
            6. æä¾›è¯¦ç»†çš„æ”¹å†™æŒ‡å¯¼ï¼ŒåŒ…æ‹¬å†…å®¹é‡ç»„ã€å™äº‹æ·±åŒ–å’Œè¡¨è¾¾ä¼˜åŒ–
            7. ç¡®ä¿æ”¹å†™ç­–ç•¥ç¬¦åˆç›®æ ‡ä¸“ä¸šå’Œå­¦æ ¡çš„ç‰¹å®šè¦æ±‚
            """,
            
            'ps_strategy_output': """
            # è¾“å‡ºæ ¼å¼
            ## PSæ”¹å†™ç­–ç•¥æŠ¥å‘Š

            ### åˆç¨¿æ€»ä½“è¯„ä¼°
            - æ•´ä½“å°è±¡ï¼š[å¯¹åˆç¨¿çš„æ€»ä½“è¯„ä»·]
            - ä¼˜åŠ¿ï¼š[åˆ—å‡º3-5ä¸ªåˆç¨¿çš„ä¸»è¦ä¼˜åŠ¿]
            - ä¸è¶³ï¼š[åˆ—å‡º3-5ä¸ªéœ€è¦æ”¹è¿›çš„æ–¹é¢]
            - ä¸ç›®æ ‡ä¸“ä¸šçš„å¥‘åˆåº¦ï¼š[è¯„ä¼°åˆç¨¿å†…å®¹ä¸ç›®æ ‡ä¸“ä¸šçš„å¥‘åˆç¨‹åº¦]

            ### å†…å®¹ç­–ç•¥
            #### ä¸“ä¸šåŠ¨æœº
            - ç°çŠ¶ï¼š[åˆç¨¿ä¸­ä¸“ä¸šåŠ¨æœºéƒ¨åˆ†çš„ç°çŠ¶]
            - å»ºè®®ï¼š[å¦‚ä½•å¼ºåŒ–æˆ–æ”¹è¿›ä¸“ä¸šåŠ¨æœºçš„è¡¨è¾¾]
            - å¯åˆ©ç”¨çš„æ”¯æŒææ–™ï¼š[ä»æ”¯æŒæ–‡ä»¶åˆ†æä¸­å¯åˆ©ç”¨çš„ç›¸å…³å†…å®¹]

            #### å­¦æœ¯èƒŒæ™¯
            - ç°çŠ¶ï¼š[åˆç¨¿ä¸­å­¦æœ¯èƒŒæ™¯éƒ¨åˆ†çš„ç°çŠ¶]
            - å»ºè®®ï¼š[å¦‚ä½•æ›´æœ‰æ•ˆåœ°å±•ç¤ºå­¦æœ¯èƒŒæ™¯]
            - å¯åˆ©ç”¨çš„æ”¯æŒææ–™ï¼š[ä»æ”¯æŒæ–‡ä»¶åˆ†æä¸­å¯åˆ©ç”¨çš„ç›¸å…³å†…å®¹]

            #### ç ”ç©¶ç»å†
            - ç°çŠ¶ï¼š[åˆç¨¿ä¸­ç ”ç©¶ç»å†éƒ¨åˆ†çš„ç°çŠ¶]
            - å»ºè®®ï¼š[å¦‚ä½•æ·±åŒ–ç ”ç©¶ç»å†çš„æè¿°]
            - å¯åˆ©ç”¨çš„æ”¯æŒææ–™ï¼š[ä»æ”¯æŒæ–‡ä»¶åˆ†æä¸­å¯åˆ©ç”¨çš„ç›¸å…³å†…å®¹]

            #### å®ä¹ ä¸å®è·µ
            - ç°çŠ¶ï¼š[åˆç¨¿ä¸­å®ä¹ ä¸å®è·µéƒ¨åˆ†çš„ç°çŠ¶]
            - å»ºè®®ï¼š[å¦‚ä½•ä¼˜åŒ–å®ä¹ ä¸å®è·µçš„å™è¿°]
            - å¯åˆ©ç”¨çš„æ”¯æŒææ–™ï¼š[ä»æ”¯æŒæ–‡ä»¶åˆ†æä¸­å¯åˆ©ç”¨çš„ç›¸å…³å†…å®¹]

            #### æœªæ¥è§„åˆ’
            - ç°çŠ¶ï¼š[åˆç¨¿ä¸­æœªæ¥è§„åˆ’éƒ¨åˆ†çš„ç°çŠ¶]
            - å»ºè®®ï¼š[å¦‚ä½•ä½¿æœªæ¥è§„åˆ’æ›´å…·è¯´æœåŠ›]
            - ä¸ç›®æ ‡ä¸“ä¸šçš„è”ç³»ï¼š[å¦‚ä½•æ›´å¥½åœ°å°†æœªæ¥è§„åˆ’ä¸ç›®æ ‡ä¸“ä¸šè”ç³»èµ·æ¥]

            ### ç»“æ„ä¸é€»è¾‘ç­–ç•¥
            - æ®µè½ç»„ç»‡ï¼š[å¯¹å½“å‰æ®µè½ç»“æ„çš„åˆ†æå’Œæ”¹è¿›å»ºè®®]
            - é€»è¾‘è¿è´¯æ€§ï¼š[å¦‚ä½•æé«˜å†…å®¹ä¹‹é—´çš„è¿è´¯æ€§]
            - å¼€å¤´ä¸ç»“å°¾ï¼š[å¦‚ä½•ä¼˜åŒ–å¼€å¤´å’Œç»“å°¾]

            ### è¡¨è¾¾ç­–ç•¥
            - è¯­è¨€é£æ ¼ï¼š[è¯­è¨€é£æ ¼çš„è¯„ä»·å’Œå»ºè®®]
            - å…·ä½“æ€§ï¼š[å¦‚ä½•ä½¿è¡¨è¾¾æ›´å…·ä½“ã€æ›´ç”ŸåŠ¨]
            - å­¦æœ¯æ€§ï¼š[å¦‚ä½•ä½¿è¡¨è¾¾æ›´åŠ å­¦æœ¯æ€§]

            ### æ”¹å†™é‡ç‚¹
            [åˆ—å‡º3-5ä¸ªæ”¹å†™çš„é‡ç‚¹ä¼˜å…ˆäº‹é¡¹]

            ### æ•´ä½“æ”¹å†™æ–¹å‘
            [æ€»ç»“æ€§åœ°æå‡ºæ•´ä½“æ”¹å†™çš„æ–¹å‘å’Œç›®æ ‡]
            """,
            
            'content_creation_role': """
            # è§’è‰²
            ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ä¸ªäººé™ˆè¿°(PS)åˆ›ä½œä¸“å®¶ï¼Œæ“…é•¿æ ¹æ®ç­–ç•¥æŒ‡å¯¼å’Œåˆ†ææŠ¥å‘Šåˆ›ä½œç²¾å½©çš„PSå†…å®¹ã€‚ä½ å…·æœ‰å“è¶Šçš„å†™ä½œæŠ€å·§å’Œä¸°å¯Œçš„ç•™å­¦ç”³è¯·æ–‡ä¹¦åˆ›ä½œç»éªŒï¼Œäº†è§£å¦‚ä½•å°†ç”³è¯·è€…çš„èƒŒæ™¯ã€ç»å†å’Œç›®æ ‡è½¬åŒ–ä¸ºå¼•äººå…¥èƒœçš„å™è¿°ã€‚
            """,
            
            'content_creation_task': """
            # ä»»åŠ¡
            1. æ ¹æ®PSæ”¹å†™ç­–ç•¥æŠ¥å‘Šä¸­çš„æŒ‡å¯¼ï¼Œåˆ›ä½œæ”¹è¿›ç‰ˆçš„ä¸ªäººé™ˆè¿°å†…å®¹
            2. éµå¾ªç­–ç•¥æŠ¥å‘Šä¸­æå‡ºçš„å†…å®¹ã€ç»“æ„å’Œè¡¨è¾¾å»ºè®®
            3. æ•´åˆæ”¯æŒæ–‡ä»¶åˆ†æä¸­çš„å…³é”®ä¿¡æ¯ï¼Œå¼ºåŒ–PSçš„è¯´æœåŠ›
            4. ç¡®ä¿å†…å®¹ä¸ç›®æ ‡ä¸“ä¸šå’Œå­¦æ ¡é«˜åº¦å¥‘åˆ
            5. ä¿æŒç”³è¯·è€…åŸæœ‰çš„ä¸ªäººé£æ ¼ï¼ŒåŒæ—¶æå‡è¡¨è¾¾è´¨é‡
            6. åˆ›ä½œæµç•…ã€è¿è´¯ã€å¼•äººå…¥èƒœçš„å™è¿°
            7. çªå‡ºç”³è¯·è€…çš„ç‹¬ç‰¹ä¼˜åŠ¿å’Œç‰¹ç‚¹
            8. ç¡®ä¿å†…å®¹çœŸå®å¯ä¿¡ï¼Œé¿å…è¿‡åº¦ä¿®é¥°æˆ–å¤¸å¼ 
            """,
            
            'content_creation_output': """
            # è¾“å‡ºæ ¼å¼
            ## ä¸ªäººé™ˆè¿°ï¼ˆ{ç›®æ ‡å­¦æ ¡} - {ç›®æ ‡ä¸“ä¸š}ï¼‰

            [åˆ›ä½œå®Œæ•´çš„ä¸ªäººé™ˆè¿°å†…å®¹ï¼Œæ ¹æ®PSç­–ç•¥æŠ¥å‘Šçš„å»ºè®®è¿›è¡Œç»„ç»‡ã€‚ä¸éœ€è¦åŒ…å«æ ‡é¢˜æˆ–åˆ†æ®µæ ‡è¯†ï¼Œç›´æ¥å‘ˆç°æµç•…çš„PSæ­£æ–‡å†…å®¹ã€‚]
            """,
            
            'transcript_role': """
            # è§’è‰²
            ä½ æ˜¯ä¸“ä¸šçš„æˆç»©å•åˆ†æå¸ˆï¼Œæ“…é•¿ä»æˆç»©å•ä¸­æå–å…³é”®ä¿¡æ¯å¹¶ä»¥è¡¨æ ¼å½¢å¼å±•ç¤ºæˆç»©ã€‚
            """,
            
            'transcript_task': """

            """,
            
            'transcript_output': """

            """,
            
            'consultant_role2': """
            # è§’è‰²
            ä½œä¸ºä¸€ä¸ªä¸“ä¸šçš„ä¸ªäººé™ˆè¿°åˆ›ä½œåŠ©æ‰‹ï¼Œæˆ‘çš„æ ¸å¿ƒèƒ½åŠ›æ˜¯:
            1. å°†åˆ†æ•£çš„ç´ ææ•´åˆæˆè¿è´¯ã€æœ‰æ·±åº¦çš„ä¸ªäººæ•…äº‹
            2. ç²¾å‡†è¯†åˆ«ç”³è¯·è€…ä¸ç›®æ ‡ä¸“ä¸šçš„å¥‘åˆç‚¹
            3. å°†å­¦æœ¯æˆå°±ä¸ä¸ªäººç»å†æœ‰æœºç»“åˆï¼Œçªå‡ºç”³è¯·è€…ä¼˜åŠ¿
            4. å°†ä¸­æ–‡ç´ æè½¬æ¢ä¸ºç¬¦åˆè‹±è¯­æ€ç»´çš„è¡¨è¾¾æ–¹å¼
            5. éµå¾ªSTARåŸåˆ™æ„å»ºæœ‰è¯´æœåŠ›çš„ç»å†æè¿°
            6. å°†æŠ½è±¡çš„å…´è¶£ä¸å…·ä½“çš„å­¦æœ¯ã€å®è·µç»å†è”ç³»èµ·æ¥
            7. ç¡®ä¿æ¯ä¸ªæ®µè½æ—¢ç‹¬ç«‹æˆç« åˆç›¸äº’å…³è”ï¼Œå½¢æˆè¿è´¯å™äº‹
            8. ä»ç”¨æˆ·æä¾›çš„ç´ æã€æˆç»©å•å’Œç”³è¯·æ–¹å‘ä¸­å‡†ç¡®æå–æœ€æœ‰ä»·å€¼çš„ä¿¡æ¯
            9. ä¸¥æ ¼éµå®ˆç´ æçœŸå®æ€§ï¼Œä¸è™šæ„æˆ–å¤¸å¤§å†…å®¹
            10. é€šè¿‡é€»è¾‘è¿æ¥å’Œè‡ªç„¶è¿‡æ¸¡æ„å»ºæµç•…çš„å™äº‹

            åœ¨æ¯æ¬¡åˆ›ä½œä¸­ï¼Œæˆ‘éƒ½ä¸“æ³¨äºè®©ç”³è¯·è€…çš„ä¸“ä¸šçƒ­æƒ…ã€å­¦æœ¯åŸºç¡€ã€ç›¸å…³ç»å†å’Œæœªæ¥è§„åˆ’å½¢æˆä¸€ä¸ªæ¸…æ™°ã€è¿è´¯ä¸”æœ‰è¯´æœåŠ›çš„æ•´ä½“ã€‚

            """,
            
            'output_format2': """
            è¾“å‡ºæ ¼å¼ï¼š
            ## ä¸ªäººé™ˆè¿°ï¼ˆä¸“ä¸šå¤§ç±»ï¼š[ä¸“ä¸šåç§°]ï¼‰

            ### ä¸“ä¸šå…´è¶£å¡‘é€ 
            > [é€‰æ‹©ä¸€ä¸ªæœ€åˆé€‚çš„è§’åº¦ï¼Œæ³¨é‡é€»è¾‘æ€§ï¼Œæ·±å…¥å±•å¼€ç»†èŠ‚æè¿°å’Œè§‚ç‚¹å™è¿°ï¼Œå‡å°‘ç´ æå †ç Œï¼Œæ³¨é‡æè¿°æ·±åº¦]

            ### å­¦æœ¯åŸºç¡€å±•ç¤º
            > [ç»“åˆç´ æè¡¨å’Œæˆç»©å•ï¼Œçªå‡º3-4ä¸ªä¸ç”³è¯·ä¸“ä¸šç›¸å…³çš„å­¦æœ¯äº®ç‚¹ï¼ŒåŒ…æ‹¬å…·ä½“è¯¾ç¨‹å†…å®¹æˆ–ä½œä¸šé¡¹ç›®çš„ç®€è¿°ä¸¾ä¾‹]

            ### ç ”ç©¶ç»å†æ·±åŒ–
            > [éµå¾ªSTARåŸåˆ™å’Œæ€»åˆ†æ€»ç»“æ„è¯¦ç»†æè¿°æœ€ç›¸å…³çš„ä¸€ä¸ªç ”ç©¶ç»å†ï¼Œä¸ä¸“ä¸šæ–¹å‘ç›¸è”ç³»]

            ### å®ä¹ ç»å†æ·±åŒ–
            > [éµå¾ªSTARåŸåˆ™å’Œæ€»åˆ†æ€»ç»“æ„è¯¦ç»†æè¿°æœ€ç›¸å…³çš„ä¸€ä¸ªå®ä¹ ç»å†ï¼Œä¸ä¸“ä¸šæ–¹å‘ç›¸è”ç³»]

            ### æœªæ¥è§„åˆ’æå‡
            > [åˆ†ä¸ºä¸‰ä¸ªå±‚æ¬¡å±•å¼€ï¼š
            > - å­¦æœ¯ç›®æ ‡
            > - èŒä¸šçŸ­æœŸè§„åˆ’
            > - èŒä¸šé•¿æœŸè§„åˆ’
            > ç¡®ä¿æ¯ä¸ªå±‚æ¬¡æœ‰æ˜ç¡®ç›®æ ‡å’Œå®ç°è·¯å¾„ï¼Œå¹¶å»ºç«‹å±‚æ¬¡é—´çš„é€’è¿›å…³ç³»]

            ### ä¸ºä½•é€‰æ‹©ç›®æ ‡å­¦æ ¡å’Œç›®æ ‡é¡¹ç›®
            > [æŒ‰ç…§é¡ºåºï¼Œä»ä»¥ä¸‹æ–¹é¢è¿›è¡Œé€šç”¨æ€§é˜è¿°ï¼š
            > 1. ç›®æ ‡å›½å®¶ä¼˜åŠ¿ï¼ˆç¦æ­¢æåŠå…·ä½“å›½å®¶ï¼ŒæåŠå›½å®¶æ—¶ï¼Œç”¨"ç›®æ ‡å›½å®¶"ä»£æ›¿ï¼‰
            > 2. ç›®æ ‡é™¢æ ¡èµ„æºä¼˜åŠ¿åŠå­¦æœ¯ç¯å¢ƒ
            > 3. ç›®æ ‡é¡¹ç›®ä¸ç ”ç©¶æ–¹å‘çš„åŒ¹é…åº¦
            > ä»è€Œå±•ç¤ºç”³è¯·è€…é€‰æ‹©çš„åˆç†æ€§]

            ##3 ç»“è¯­
            > [ç®€æ´æœ‰åŠ›åœ°æ€»ç»“ç”³è¯·è€…çš„ä¼˜åŠ¿ã€å¿—å‘å’Œå¯¹è¯¥ä¸“ä¸šçš„çƒ­æƒ…]


            ç»“æ„è¦æ±‚ï¼š
            1. ç¬¬ä¸€æ®µ(ä¸“ä¸šå…´è¶£å¡‘é€ )ï¼š
            - é€‰æ‹©æœ€åˆé€‚çš„ä¸€ä¸ªè§’åº¦(è¿‡å»ç»å†/æ—¶äº‹æ–°é—»/ç§‘ç ”æˆæœ)ä½œä¸ºæ ¸å¿ƒçº¿ç´¢å±•å¼€
            - å»ºç«‹æ¸…æ™°çš„æ€ç»´å‘å±•è·¯å¾„ï¼šä»åˆå§‹æ¥è§¦â†’æ·±å…¥æ¢ç´¢â†’è®¤è¯†æ·±åŒ–â†’ä¸“ä¸šæ–¹å‘ç¡®å®š
            - ä½¿ç”¨å…·ä½“ä¾‹å­æ”¯æ’‘æŠ½è±¡æ¦‚å¿µï¼Œé€šè¿‡ç»†èŠ‚å±•ç¤ºæ€è€ƒæ·±åº¦
            - æ¯å¥è¯åº”ä¸å‰å¥æœ‰æ˜ç¡®çš„é€»è¾‘å…³è”ï¼Œä½¿ç”¨æ°å½“çš„è¿‡æ¸¡è¯å±•ç¤ºæ€ç»´è¿è´¯æ€§
            - é¿å…ç®€å•ç½—åˆ—å¤šä¸ªç´ æç‚¹ï¼Œè€Œæ˜¯æ·±å…¥å‘å±•å•ä¸€ä¸»çº¿
            - ç»“å°¾å¤„åº”ä¸æœªæ¥å­¦ä¹ æ–¹å‘è‡ªç„¶è¡”æ¥ï¼Œä¸ºåç»­æ®µè½é“ºå«
            2.ç¬¬äºŒæ®µ(å­¦æœ¯åŸºç¡€å±•ç¤º)ï¼šç»“åˆç´ æè¡¨+æˆç»©å•ï¼Œæ‰¾åˆ°3-4ä¸ªä¸ç”³è¯·ä¸“ä¸šç›¸å…³çš„å­¦æœ¯äº®ç‚¹(åŒ…æ‹¬ä½†ä¸é™äºä¸ç”³è¯·ä¸“ä¸šç›¸å…³çš„ä¸“ä¸šçŸ¥è¯†ã€å­¦æœ¯èƒ½åŠ›å’Œä¸“ä¸šæŠ€èƒ½)ï¼Œè¿›è¡Œé˜è¿°ï¼Œå¹¶æœ‰å…·ä½“è¯¾ç¨‹å†…å®¹æˆ–ä½œä¸šé¡¹ç›®çš„ç®€è¿°ä¸¾ä¾‹3. æ¯ä¸ªæ®µè½åº”é‡‡ç”¨"æ€»-åˆ†-æ€»"ç»“æ„ï¼Œç¬¬ä¸€å¥è¯æ‰¿ä¸Šå¯ä¸‹ï¼Œæœ€åä¸€å¥è¯æ€»ç»“è¯¥ç»å†ä¸ç›®æ ‡ä¸“ä¸šçš„è”ç³»
            3.æ§åˆ¶æ•´ä½“å­—æ•°ï¼Œæ¯ä¸ªæ®µè½æ§åˆ¶åœ¨150-200å­—å·¦å³ï¼Œç¡®ä¿æ–‡ä¹¦ç´§å‡‘ç²¾ç‚¼
            4.å¢å¼ºå¥å­ä¹‹é—´çš„é€»è¾‘è¿æ¥ï¼š
            - ç¡®ä¿æ¯ä¸ªæ–°å¥å­åŒ…å«å‰ä¸€å¥å­çš„å…³é”®è¯æˆ–æ¦‚å¿µ
            - ä½¿ç”¨æŒ‡ä»£è¯æ˜ç¡®å¼•ç”¨å‰æ–‡å†…å®¹
            - æ°å½“ä½¿ç”¨è¿‡æ¸¡è¯å’Œè¿æ¥è¯
            - å»ºç«‹æ¸…æ™°çš„å› æœå…³ç³»ï¼Œä½¿ç”¨"å› æ­¤"ã€"ç”±æ­¤"ã€"æ­£æ˜¯"ç­‰è¯è¯­æ˜ç¡®å‰åå¥å…³ç³»
            - é‡‡ç”¨é€’è¿›ç»“æ„å±•ç¤ºæ€æƒ³å‘å±•ï¼Œä»åˆå§‹è§‚å¯Ÿåˆ°æ·±å…¥æ€è€ƒï¼Œå†åˆ°å½¢æˆæ ¸å¿ƒè§‚ç‚¹
            - æ·»åŠ è¿‡æ¸¡å¥ç¡®ä¿å„ç‚¹ä¹‹é—´è‡ªç„¶è¡”æ¥ï¼Œå¦‚"è¿™ç§è®¤è¯†å¼•å¯¼æˆ‘..."ã€"é€šè¿‡è¿™ä¸€æ¢ç´¢..."
            - ç¡®ä¿æ¯ä¸ªæ®µè½å½¢æˆå®Œæ•´çš„æ€æƒ³å‘å±•è„‰ç»œï¼Œå±•ç°è®¤çŸ¥çš„æ·±åŒ–è¿‡ç¨‹
            - é¿å…å•çº¯å¹¶åˆ—ä¸ç›¸å…³ä¿¡æ¯ï¼Œè€Œæ˜¯é€šè¿‡é€»è¾‘è¯å»ºç«‹å†…åœ¨è”ç³»



            """,
            
            'consultant_task2': """
            ä»»åŠ¡æè¿°:
            1. åŸºäºæä¾›çš„ç´ æè¡¨ã€æˆç»©å•(å¦‚æœ‰)ã€ç”³è¯·æ–¹å‘åŠä¸ªæ€§åŒ–éœ€æ±‚(å¦‚æœ‰)ï¼Œä¸ºæŒ‡å®šä¸“ä¸šæ–¹å‘åˆ›ä½œå®Œæ•´çš„ä¸ªäººé™ˆè¿°åˆç¨¿
            2. å……åˆ†åˆ©ç”¨ç”¨æˆ·æä¾›çš„å››ç±»ä¿¡æ¯(ç´ æè¡¨ã€æˆç»©å•ã€ç”³è¯·æ–¹å‘ã€ä¸ªæ€§åŒ–éœ€æ±‚)ï¼Œè¿›è¡Œæ·±åº¦åˆ†æå’Œå†…å®¹åˆ›ä½œ
            3. éµå¾ªSTARåŸåˆ™(æƒ…å¢ƒ-ä»»åŠ¡-è¡ŒåŠ¨-ç»“æœ)å‘ˆç°ç ”ç©¶ç»å†å’Œå®ä¹ ç»å†ï¼Œä¸”åªé€‰æ‹©ç´ æä¸­æœ€ç›¸å…³çš„ä¸€ä¸ªç»å†
            4. çªå‡ºç”³è¯·è€…ä¸ç”³è¯·æ–¹å‘çš„å¥‘åˆç‚¹
            5. åœ¨æ­£æ–‡ä¸­ç›´æ¥ä½¿ç”¨ã€è¡¥å……ï¼šã€‘æ ‡è®°æ‰€æœ‰éç´ æè¡¨ä¸­çš„å†…å®¹
            6. ç¡®ä¿æ®µè½é—´æœ‰è‡ªç„¶è¿‡æ¸¡ï¼Œä¿æŒæ–‡ç« æ•´ä½“è¿è´¯æ€§
            7. æ‰€æœ‰æ®µè½ä¸­çš„äº‹å®å†…å®¹å¿…é¡»ä¸¥æ ¼éµå¾ªç´ æè¡¨ï¼Œä¸æ·»åŠ æœªåœ¨ç´ æè¡¨ä¸­å‡ºç°çš„å†…å®¹
            8. ä¼˜åŒ–è¡¨è¿°é€»è¾‘ï¼Œç¡®ä¿å†…å®¹ä¹‹é—´çš„è¿è´¯æ€§å’Œè‡ªç„¶è¿‡æ¸¡
            9. æ ¸å¿ƒçš„ç»å†ä¼˜å…ˆæ”¾å…¥ç»å†æ®µè½ï¼Œé¿å…ä¸€ä¸ªç»å†å¤šæ¬¡ä½¿ç”¨ï¼Œé™¤éç”¨æˆ·ç‰¹åˆ«è¦æ±‚

            å†™ä½œè¯´æ˜ï¼š
            â— ç¡®ä¿æ–‡ç« ç»“æ„æ¸…æ™°ï¼Œæ®µè½ä¹‹é—´æœ‰è‰¯å¥½çš„é€»è¾‘è¿‡æ¸¡
            â— æ‰€æœ‰éç´ æè¡¨ä¸­éœ€è¦è¡¥å……çš„å†…å®¹å¿…é¡»ä¿ç•™ä¸­æ–‡å¹¶ç”¨ã€è¡¥å……ï¼šã€‘æ ‡è®°
            â— å†…å®¹å‡ä½¿ç”¨çº¯ä¸­æ–‡è¡¨è¾¾
            â— æŠ€æœ¯æœ¯è¯­å’Œä¸“ä¸šæ¦‚å¿µåˆ™ä½¿ç”¨å‡†ç¡®çš„è‹±æ–‡è¡¨è¾¾
            â— ä¿æŒæ–‡ç« çš„æ•´ä½“è¿è´¯æ€§å’Œä¸“ä¸šæ€§
            â— é‡ç‚¹çªå‡ºç”³è¯·è€…çš„ä¼˜åŠ¿ï¼Œå¹¶ä¸ç”³è¯·æ–¹å‘å»ºç«‹æ˜ç¡®è”ç³»
            â— å†…å®¹åº”çœŸå®å¯ä¿¡ï¼Œé¿å…è™šæ„ç»å†æˆ–å¤¸å¤§æˆå°±
            â— æ¯ä¸ªä¸»é¢˜éƒ¨åˆ†åº”å½“æ˜¯ä¸€ä¸ªè¿è´¯çš„æ•´ä½“æ®µè½ï¼Œè€Œéå¤šä¸ªæ¾æ•£æ®µè½
            â— åœ¨åˆ†ææˆç»©å•æ—¶ï¼Œå…³æ³¨ä¸ç”³è¯·ä¸“ä¸šç›¸å…³çš„è¯¾ç¨‹è¡¨ç°ï¼Œä½†ä¸è¦ä½“ç°ä»»ä½•åˆ†æ•°
            â— ç¡®ä¿å†…å®¹ç²¾ç»ƒï¼Œé¿å…ä¸å¿…è¦çš„é‡å¤å’Œå†—ä½™è¡¨è¾¾
            â— ç»“è¯­åº”ç®€æ˜æ‰¼è¦åœ°æ€»ç»“å…¨æ–‡ï¼Œå±•ç°ç”³è¯·è€…çš„å†³å¿ƒå’Œæ„¿æ™¯
            â— é¿å…å‡ºç°"çªç„¶æ„Ÿå…´è¶£"æˆ–"å› æ­¤æ›´æ„Ÿå…´è¶£"ç­‰ç”Ÿç¡¬è½¬æŠ˜ï¼Œç¡®ä¿å…´è¶£å‘å±•æœ‰åˆç†çš„æ¸è¿›è¿‡ç¨‹
            â— å„æ®µè½é—´åº”æœ‰å†…åœ¨çš„é€»è¾‘è”ç³»ï¼Œè€Œéç®€å•ç½—åˆ—ï¼Œæ¯æ®µå†…å®¹åº”è‡ªç„¶å¼•å‡ºä¸‹ä¸€æ®µå†…å®¹
            â— ç¡®ä¿ç»å†ä¸ä¸“ä¸šå…´è¶£é—´çš„å…³è”æ€§å…·æœ‰è¯´æœåŠ›ï¼Œå±•ç¤ºæ¸…æ™°çš„æ€ç»´å‘å±•è·¯å¾„
            â— å¿…é¡»å……åˆ†ç†è§£å’Œæ‰§è¡Œç”¨æˆ·çš„ä¸ªæ€§åŒ–éœ€æ±‚(å¦‚æœ‰)
            â— ç¡®ä¿æ•´ä½“å™äº‹å…·æœ‰å†…åœ¨ä¸€è‡´æ€§å’Œåˆç†çš„å¿ƒç†åŠ¨æœºå‘å±•
            â— æ ¸å¿ƒç»å†åº”åªå‡ºç°åœ¨å¯¹åº”çš„ç»å†æ®µè½ä¸­ï¼Œé¿å…é‡å¤ä½¿ç”¨åŒä¸€ç»å†ï¼Œé™¤éç”¨æˆ·ç‰¹åˆ«è¦æ±‚



            """,
            "material_simplifier_role": """
            è¯¥æŒ‡ä»¤ç”¨äºå°†ä¸ªäººé™ˆè¿°è°ƒæŸ¥é—®å·ä¸­çš„é›¶æ•£ä¿¡æ¯è½¬åŒ–ä¸ºç»“æ„åŒ–çš„è¦ç‚¹åˆ—è¡¨ï¼Œä»¥ä¾¿äºæ’°å†™ç•™å­¦ç”³è¯·ææ–™ã€‚
            è¿™ä¸€è¿‡ç¨‹éœ€è¦ç¡®ä¿æ‰€æœ‰ä¿¡æ¯è¢«æ­£ç¡®å½’ç±»ï¼ŒåŒæ—¶å½»åº•ç§»é™¤ä»»ä½•å­¦æ ¡å’Œä¸“ä¸šå…·ä½“ä¿¡æ¯ï¼Œä»¥ä¿æŒç”³è¯·ææ–™çš„é€šç”¨æ€§ä¸é€‚ç”¨æ€§ã€‚
            ç•™å­¦ç”³è¯·ä¸­ï¼Œä¸ªäººé™ˆè¿°æ˜¯å±•ç¤ºç”³è¯·è€…èƒŒæ™¯ã€ç»å†ã€ä¸“ä¸šå…´è¶£ä»¥åŠæœªæ¥è§„åˆ’çš„å…³é”®ææ–™ï¼Œä½†åŸå§‹è°ƒæŸ¥é—®å·é€šå¸¸åŒ…å«å¤§é‡æœªç»æ•´ç†çš„ä¿¡æ¯ï¼Œä¸”å¯èƒ½åŒ…å«è¿‡äºå…·ä½“çš„å­¦æ ¡å’Œä¸“ä¸šä¿¡æ¯ï¼Œéœ€è¦è¿›è¡Œä¸“ä¸šåŒ–çš„æ•´ç†ä¸å½’ç±»ã€‚


            """,
            "material_simplifier_task": """
            1. å¤„ç†æµç¨‹ï¼š
                - ä»”ç»†é˜…è¯»æä¾›çš„ä¸ªäººé™ˆè¿°è°ƒæŸ¥é—®å·ç´ æ
                - å°†ç´ æä¸­çš„ä¿¡æ¯æŒ‰ç…§ç»Ÿä¸€æ ¼å¼æå–
                - åˆ é™¤å­¦æ ¡å’Œä¸“ä¸šåç§°çš„åŒæ—¶ä¿ç•™é¡¹ç›®å®è´¨å†…å®¹
                - æŒ‰ç…§ä¸ªäººé™ˆè¿°ç´ æè¡¨çš„ä¸ƒå¤§æ¡†æ¶è¿›è¡Œåˆ†ç±»æ•´ç†
                - ä½¿ç”¨è§„å®šæ ¼å¼è¾“å‡ºæœ€ç»ˆç»“æœ

            2. å…³é”®è¦æ±‚ï¼š
                - åˆ é™¤æ ‡è¯†æ€§ä¿¡æ¯ä½†ä¿ç•™å†…å®¹ï¼š
                    * åˆ é™¤å¤§å­¦åç§°ã€ç¼©å†™å’Œåˆ«ç§°ï¼Œä½†ä¿ç•™åœ¨è¯¥æ ¡å®Œæˆçš„é¡¹ç›®ã€ç ”ç©¶æˆ–ç»å†çš„å…·ä½“å†…å®¹
                    * åˆ é™¤å®éªŒå®¤ã€ç ”ç©¶ä¸­å¿ƒçš„å…·ä½“åç§°ï¼Œä½†ä¿ç•™å…¶ç ”ç©¶æ–¹å‘å’Œå†…å®¹
                    * åˆ é™¤ç‰¹å®šå­¦ä½é¡¹ç›®åç§°å’Œç¼–å·ï¼Œä½†ä¿ç•™è¯¾ç¨‹å†…å®¹
                    * åˆ é™¤æ•™æˆã€å¯¼å¸ˆçš„å§“åå’Œå¤´è¡”ï¼Œä½†ä¿ç•™ä¸å…¶åˆä½œçš„é¡¹ç›®å†…å®¹
                
                - ä¿ç•™è¯¾ç¨‹å’Œç»å†ç»†èŠ‚ï¼š
                    * è¯¾ç¨‹å†…å®¹ã€é¡¹ç›®æè¿°ã€æŠ€èƒ½åŸ¹å…»ç­‰ç»†èŠ‚å¿…é¡»å®Œæ•´ä¿ç•™
                    * è¯¾ç¨‹ä¿ç•™å…·ä½“è¯¾ç¨‹ç¼–å·åŠè¯¾ç¨‹åç§°
                    * é¡¹ç›®ç»å†çš„æŠ€æœ¯ç»†èŠ‚ã€æ–¹æ³•è®ºã€å·¥å…·ä½¿ç”¨ç­‰ä¿¡æ¯å¿…é¡»ä¿ç•™
                    * ä¿ç•™æ‰€æœ‰æˆæœæ•°æ®ã€è·å¥–æƒ…å†µï¼ˆç§»é™¤å…·ä½“å­¦æ ¡åç§°ï¼‰
                    * å³ä½¿é¡¹ç›®æ˜¯åœ¨ç‰¹å®šå­¦æ ¡å®Œæˆçš„ï¼Œä¹Ÿå¿…é¡»ä¿ç•™é¡¹ç›®çš„å…¨éƒ¨å®è´¨å†…å®¹
                
                - ä¿¡æ¯åˆ†ç±»å¿…é¡»ç²¾ç¡®æ— è¯¯ï¼š
                    * æ¯æ¡ä¿¡æ¯å¿…é¡»ä¸”åªèƒ½å½’å…¥ä¸€ä¸ªç±»åˆ«
                    * ä¸¥æ ¼éµå¾ª"ä¸ƒå¤§æ¡†æ¶"çš„åˆ†ç±»æ ‡å‡†
                    * ä¸å…è®¸åˆ›å»ºæ–°ç±»åˆ«æˆ–åˆå¹¶ç°æœ‰ç±»åˆ«
                    * ä¸å…è®¸åŒä¸€ä¿¡æ¯è·¨ç±»åˆ«é‡å¤å‡ºç°
                
                - ç»å†è¦ç‚¹æ ¼å¼è¦æ±‚ï¼š
                    * ç ”ç©¶ã€å®ä¹ å’Œå®è·µç»å†å¿…é¡»æŒ‰ç…§ä¸ƒä¸ªå­è¦ç‚¹åˆ†è¡Œæ˜¾ç¤º
                    * å¦‚æŸäº›è¦ç´ ç¼ºå¤±ï¼Œä¿æŒé¡ºåºä¸å˜å¹¶è·³è¿‡è¯¥è¦ç´ 
                    * é¡¹ç›®å†…å®¹æè¿°å¿…é¡»åŒ…å«é¡¹ç›®æ‰€ç»å†çš„å®Œæ•´æ­¥éª¤å’Œæµç¨‹
                    * ä¸ªäººèŒè´£å¿…é¡»è¯¦ç»†åˆ—å‡ºæ‰€æœ‰è´£ä»»ã€é‡åˆ°çš„å›°éš¾åŠè§£å†³æ–¹æ¡ˆ

            """,

            "material_simplifier_output":"""
            è¾“å‡ºæ ‡é¢˜ä¸º"ä¸ªäººé™ˆè¿°ç´ ææ•´ç†æŠ¥å‘Š"ï¼Œä»…åŒ…å«ä»¥ä¸‹ä¸ƒä¸ªéƒ¨åˆ†ï¼š

            1. ä¸“ä¸šå…´è¶£å¡‘é€ 
            - ä»…åŒ…å«ä¸“ä¸šå…´è¶£å½¢æˆè¿‡ç¨‹çš„è¦ç‚¹åˆ—è¡¨
            - æ¯ä¸ªè¦ç‚¹ä»¥å•ä¸ªçŸ­æ¨ªçº¿"-"å¼€å¤´
            - ä¿ç•™æ‰€æœ‰æ¿€å‘å…´è¶£çš„ç»†èŠ‚ç»å†å’Œä½“éªŒ

            2. å­¦æœ¯åŸºç¡€å±•ç¤º
            - ä»…åŒ…å«è¯¾ç¨‹å­¦ä¹ ã€å­¦æœ¯é¡¹ç›®ã€æ•™è‚²èƒŒæ™¯çš„è¦ç‚¹åˆ—è¡¨
            - æ¯ä¸ªè¦ç‚¹ä»¥å•ä¸ªçŸ­æ¨ªçº¿"-"å¼€å¤´
            - ä¿ç•™è¯¾ç¨‹å†…å®¹ã€å­¦ä¹ æˆæœå’ŒæŠ€èƒ½åŸ¹å…»çš„è¯¦ç»†æè¿°

            3. ç ”ç©¶ç»å†æ·±åŒ–
            - æ¯ä¸ªç ”ç©¶ç»å†ä½œä¸ºä¸€ä¸ªä¸»è¦è¦ç‚¹ï¼ŒåŒ…å«ä¸ƒä¸ªåˆ†è¡Œæ˜¾ç¤ºçš„å­è¦ç‚¹ï¼š
                - é¡¹ç›®åç§°ï¼š[å†…å®¹]
                - å…·ä½“æ—¶é—´ï¼š[å†…å®¹]
                - æ‰®æ¼”çš„è§’è‰²ï¼š[å†…å®¹]
                - é¡¹ç›®å†…å®¹æè¿°ï¼š[è¯¦ç»†æè¿°é¡¹ç›®çš„å…¨éƒ¨æ­¥éª¤ã€èƒŒæ™¯ã€ç›®æ ‡å’Œå®æ–½è¿‡ç¨‹]
                - ä¸ªäººèŒè´£ï¼š[è¯¦ç»†æè¿°æ‰€æœ‰è´£ä»»ã€é‡åˆ°çš„å›°éš¾åŠè§£å†³æ–¹æ¡ˆ]
                - å–å¾—çš„æˆæœï¼š[å†…å®¹]
                - ç»å†æ„Ÿæ‚Ÿï¼š[å†…å®¹]

            4. å®ä¹ ç»å†æ·±åŒ–
            - æ¯ä¸ªå®ä¹ ç»å†ä½œä¸ºä¸€ä¸ªä¸»è¦è¦ç‚¹ï¼ŒåŒ…å«ä¸ƒä¸ªåˆ†è¡Œæ˜¾ç¤ºçš„å­è¦ç‚¹ï¼š
                - é¡¹ç›®åç§°ï¼š[å†…å®¹]
                - å…·ä½“æ—¶é—´ï¼š[å†…å®¹]
                - æ‰®æ¼”çš„è§’è‰²ï¼š[å†…å®¹]
                - é¡¹ç›®å†…å®¹æè¿°ï¼š[è¯¦ç»†æè¿°é¡¹ç›®çš„å…¨éƒ¨æ­¥éª¤ã€èƒŒæ™¯ã€ç›®æ ‡å’Œå®æ–½è¿‡ç¨‹]
                - ä¸ªäººèŒè´£ï¼š[è¯¦ç»†æè¿°æ‰€æœ‰è´£ä»»ã€é‡åˆ°çš„å›°éš¾åŠè§£å†³æ–¹æ¡ˆ]
                - å–å¾—çš„æˆæœï¼š[å†…å®¹]
                - ç»å†æ„Ÿæ‚Ÿï¼š[å†…å®¹]

            5. å®è·µç»å†è¡¥å……
            - æ¯ä¸ªå®è·µç»å†ä½œä¸ºä¸€ä¸ªä¸»è¦è¦ç‚¹ï¼ŒåŒ…å«ä¸ƒä¸ªåˆ†è¡Œæ˜¾ç¤ºçš„å­è¦ç‚¹ï¼š
                - é¡¹ç›®åç§°ï¼š[å†…å®¹]
                - å…·ä½“æ—¶é—´ï¼š[å†…å®¹]
                - æ‰®æ¼”çš„è§’è‰²ï¼š[å†…å®¹]
                - é¡¹ç›®å†…å®¹æè¿°ï¼š[è¯¦ç»†æè¿°é¡¹ç›®çš„å…¨éƒ¨æ­¥éª¤ã€èƒŒæ™¯ã€ç›®æ ‡å’Œå®æ–½è¿‡ç¨‹]
                - ä¸ªäººèŒè´£ï¼š[è¯¦ç»†æè¿°æ‰€æœ‰è´£ä»»ã€é‡åˆ°çš„å›°éš¾åŠè§£å†³æ–¹æ¡ˆ]
                - å–å¾—çš„æˆæœï¼š[å†…å®¹]
                - ç»å†æ„Ÿæ‚Ÿï¼š[å†…å®¹]

            6. æœªæ¥è§„åˆ’æå‡
            - ä»…åŒ…å«å­¦ä¹ è®¡åˆ’ã€èŒä¸šè§„åˆ’ã€å‘å±•æ–¹å‘çš„è¦ç‚¹åˆ—è¡¨
            - æ¯ä¸ªè¦ç‚¹ä»¥å•ä¸ªçŸ­æ¨ªçº¿"-"å¼€å¤´
            - ä¿ç•™æ‰€æœ‰æ—¶é—´èŠ‚ç‚¹å’Œå…·ä½“è§„åˆ’ç»†èŠ‚

            7. ä¸ºä½•é€‰æ‹©è¯¥ä¸“ä¸šå’Œé™¢æ ¡
            - ä»…åŒ…å«é€‰æ‹©åŸå› ã€å›½å®¶ä¼˜åŠ¿çš„è¦ç‚¹åˆ—è¡¨ï¼ˆä¸å«å…·ä½“å­¦æ ¡ä¿¡æ¯ï¼‰
            - æ¯ä¸ªè¦ç‚¹ä»¥å•ä¸ªçŸ­æ¨ªçº¿"-"å¼€å¤´
            - ä¿ç•™å¯¹ä¸“ä¸šé¢†åŸŸã€ç ”ç©¶æ–¹å‘çš„å…·ä½“å…´è¶£æè¿°

            ç¦æ­¢æ·»åŠ ä»»ä½•éè¦æ±‚çš„æ ‡é¢˜ã€æ³¨é‡Šæˆ–æ€»ç»“ã€‚

            """
        }
        
        # åˆå§‹åŒ– session_state ä¸­çš„æ¨¡æ¿
        if 'templates' not in st.session_state:
            st.session_state.templates = self.default_templates.copy()

    def get_template(self, template_name: str) -> str:
        return st.session_state.templates.get(template_name, "")

    def update_template(self, template_name: str, new_content: str) -> None:
        st.session_state.templates[template_name] = new_content

    def reset_to_default(self):
        st.session_state.templates = self.default_templates.copy()

class TranscriptAnalyzer:
    def __init__(self, api_key: str, prompt_templates: PromptTemplates):
        self.prompt_templates = prompt_templates
        if 'templates' not in st.session_state:
            st.session_state.templates = self.prompt_templates.default_templates.copy()
            
        self.llm = ChatOpenAI(
            temperature=0.1,
            model=st.session_state.transcript_model,  # ä½¿ç”¨session stateä¸­çš„æ¨¡å‹
            api_key=api_key,
            base_url="https://openrouter.ai/api/v1",
            streaming=True
        )
        
        # æ·»åŠ ææ–™ç®€åŒ–å™¨LLMï¼Œä½¿ç”¨æˆæœ¬è¾ƒä½çš„æ¨¡å‹
        self.simplifier_llm = ChatOpenAI(
            temperature=0.1,
            model=st.session_state.simplifier_model,  # ä½¿ç”¨session stateä¸­çš„ç®€åŒ–å™¨æ¨¡å‹
            api_key=api_key,
            base_url="https://openrouter.ai/api/v1",
            streaming=True
        )
        self.setup_simplifier_chains()

    def extract_images_from_pdf(self, pdf_bytes):
        """ä»PDFä¸­æå–å›¾åƒ"""
        try:
            images = []
            pdf_document = fitz.open(stream=pdf_bytes, filetype="pdf")
            
            for page_num in range(len(pdf_document)):
                page = pdf_document[page_num]
                # å°†é¡µé¢ç›´æ¥è½¬æ¢ä¸ºå›¾åƒ
                pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))
                img_bytes = pix.tobytes("png")
                # å°†å›¾åƒç¼–ç ä¸ºbase64å­—ç¬¦ä¸²
                img_base64 = base64.b64encode(img_bytes).decode('utf-8')
                images.append(img_base64)
            
            return images
        except Exception as e:
            logger.error(f"æå–PDFå›¾åƒæ—¶å‡ºé”™: {str(e)}")
            return []
    
    def analyze_transcript(self, pdf_bytes) -> Dict[str, Any]:
        try:
            if not hasattr(self, 'prompt_templates'):
                logger.error("prompt_templates not initialized")
                raise ValueError("Prompt templates not initialized properly")
            
            images = self.extract_images_from_pdf(pdf_bytes)
            if not images:
                return {
                    "status": "error",
                    "message": "æ— æ³•ä»PDFä¸­æå–å›¾åƒ"
                }
            
            # ä¿®æ”¹æ¶ˆæ¯æ ¼å¼
            messages = [
                SystemMessage(content=self.prompt_templates.get_template('transcript_role')),
                HumanMessage(content=[  # æ³¨æ„è¿™é‡Œæ”¹æˆäº†åˆ—è¡¨
                    {
                        "type": "text",
                        "text": f"\n\nè¯·åˆ†æè¿™ä»½æˆç»©å•ï¼Œæå–æˆç»©ä¿¡æ¯ï¼Œå¹¶ä»¥è¡¨æ ¼å½¢å¼è¾“å‡ºæˆç»©ä¿¡æ¯ã€‚"
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/png;base64,{images[0]}"
                        }
                    }
                ])
            ]
            
            # åˆ›å»ºä¸€ä¸ªé˜Ÿåˆ—ç”¨äºæµå¼è¾“å‡º
            message_queue = Queue()
            
            # åˆ›å»ºè‡ªå®šä¹‰å›è°ƒå¤„ç†å™¨
            class QueueCallbackHandler(BaseCallbackHandler):
                def __init__(self, queue):
                    self.queue = queue
                    super().__init__()
                
                def on_llm_new_token(self, token: str, **kwargs) -> None:
                    self.queue.put(token)
            
            # åˆ›å»ºä¸€ä¸ªç”Ÿæˆå™¨å‡½æ•°ï¼Œç”¨äºæµå¼è¾“å‡º
            def token_generator():
                while True:
                    try:
                        token = message_queue.get(block=False)
                        yield token
                    except Empty:
                        if not thread.is_alive() and message_queue.empty():
                            break
                    time.sleep(0.01)
            
            # åœ¨å•ç‹¬çš„çº¿ç¨‹ä¸­è¿è¡Œåˆ†æ
            def run_analysis():
                try:
                    # è°ƒç”¨LLMè¿›è¡Œåˆ†æ
                    chain = LLMChain(llm=self.llm, prompt=ChatPromptTemplate.from_messages(messages))
                    result = chain.run(
                        {},
                        callbacks=[QueueCallbackHandler(message_queue)]
                    )
                    
                    message_queue.put("\n\næˆç»©å•åˆ†æå®Œæˆï¼")
                    thread.result = result
                    return result
                    
                except Exception as e:
                    message_queue.put(f"\n\né”™è¯¯: {str(e)}")
                    logger.error(f"æˆç»©å•åˆ†æé”™è¯¯: {str(e)}")
                    thread.exception = e
                    raise e
            
            # å¯åŠ¨çº¿ç¨‹
            thread = Thread(target=run_analysis)
            thread.start()
            
            # ç”¨äºæµå¼è¾“å‡ºçš„å®¹å™¨
            output_container = st.empty()
            
            # æµå¼è¾“å‡º
            with output_container:
                full_response = st.write_stream(token_generator())
            
            # ç­‰å¾…çº¿ç¨‹å®Œæˆ
            thread.join()
            
            # æ¸…ç©ºåŸå®¹å™¨å¹¶ä½¿ç”¨markdowné‡æ–°æ¸²æŸ“å®Œæ•´å“åº”
            if full_response:
                output_container.empty()
                output_container.markdown(full_response)
            
            # è·å–ç»“æœ
            if hasattr(thread, "exception") and thread.exception:
                raise thread.exception
            
            logger.info("æˆç»©å•åˆ†æå®Œæˆ")
            
            return {
                "status": "success",
                "transcript_analysis": full_response
            }
                
        except Exception as e:
            logger.error(f"æˆç»©å•åˆ†æé”™è¯¯: {str(e)}")
            return {
                "status": "error",
                "message": str(e)
            }
    
    def setup_simplifier_chains(self):
            # ç®€åŒ–ç´ æè¡¨ Chain
            simplifier_prompt = ChatPromptTemplate.from_messages([
                ("system", f"{self.prompt_templates.get_template('material_simplifier_role')}\n\n"
                        f"ä»»åŠ¡:\n{self.prompt_templates.get_template('material_simplifier_tesk')}\n\n"
                        f"è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡º:\n{self.prompt_templates.get_template('material_simplifier_output')}"),
                ("human", "ç´ æè¡¨document_contentï¼š\n{document_content}")
            ])
            
            self.simplifier_chain = LLMChain(
                llm=self.simplifier_llm,
                prompt=simplifier_prompt,
                output_key="simplifier_result",
                verbose=True
            )
    
    def simplify_materials(self, document_content: str) -> Dict[str, Any]:
        """ç®€åŒ–ç´ æè¡¨å†…å®¹"""
        try:
            # åˆ›å»ºä¸€ä¸ªé˜Ÿåˆ—ç”¨äºæµå¼è¾“å‡º
            message_queue = Queue()
            
            # åˆ›å»ºè‡ªå®šä¹‰å›è°ƒå¤„ç†å™¨ï¼Œç»§æ‰¿è‡ª BaseCallbackHandler
            class QueueCallbackHandler(BaseCallbackHandler):
                def __init__(self, queue):
                    self.queue = queue
                    super().__init__()
                
                def on_llm_new_token(self, token: str, **kwargs) -> None:
                    self.queue.put(token)
            
            # åˆ›å»ºä¸€ä¸ªç”Ÿæˆå™¨å‡½æ•°ï¼Œç”¨äºæµå¼è¾“å‡º
            def token_generator():
                while True:
                    try:
                        token = message_queue.get(block=False)
                        yield token
                    except Empty:
                        if not thread.is_alive() and message_queue.empty():
                            break
                    time.sleep(0.01)
            
            # åœ¨å•ç‹¬çš„çº¿ç¨‹ä¸­è¿è¡ŒLLM
            def run_llm():
                try:
                    result = self.simplifier_chain(
                        {
                            "document_content": document_content
                        },
                        callbacks=[QueueCallbackHandler(message_queue)]
                    )
                    # å°†ç»“æœå­˜å‚¨åœ¨çº¿ç¨‹å¯¹è±¡ä¸­
                    thread.result = result
                    message_queue.put("\n\nç®€åŒ–å®Œæˆï¼")
                    return result
                except Exception as e:
                    message_queue.put(f"\n\né”™è¯¯: {str(e)}")
                    logger.error(f"ç®€åŒ–ç´ æè¡¨æ—¶å‡ºé”™: {str(e)}")
                    thread.exception = e
                    raise e
            
            # å¯åŠ¨çº¿ç¨‹
            thread = Thread(target=run_llm)
            thread.start()
            with st.expander("ç®€åŒ–åçš„ç´ æè¡¨", expanded=True):
                # åˆ›å»ºæµå¼è¾“å‡ºå®¹å™¨
                output_container = st.empty()
                
                # æµå¼è¾“å‡º
                with output_container:
                    full_response = st.write_stream(token_generator())
                
                # ç­‰å¾…çº¿ç¨‹å®Œæˆ
                thread.join()
                
                # æ¸…ç©ºåŸå®¹å™¨å¹¶ä½¿ç”¨markdowné‡æ–°æ¸²æŸ“å®Œæ•´å“åº”
                if full_response:
                # å¤„ç†å¯èƒ½å­˜åœ¨çš„markdownä»£ç å—æ ‡è®°
                    if full_response.startswith("```markdown"):
                        # ç§»é™¤å¼€å¤´çš„```markdownå’Œç»“å°¾çš„```
                        full_response = full_response.replace("```markdown", "", 1)
                        if full_response.endswith("```"):
                            full_response = full_response[:-3]
                    
                    output_container.empty()
                    new_container = st.container()
                    with new_container:
                        st.markdown(full_response)
                
                # è·å–ç»“æœ
                if hasattr(thread, "exception") and thread.exception:
                    raise thread.exception
                
                logger.info("simplifier_result completed successfully")
                
                # ä» full_response ä¸­æå–åˆ†æç»“æœ
                processed_response = full_response
                if processed_response.startswith("```markdown"):
                    # ç§»é™¤å¼€å¤´çš„```markdownå’Œç»“å°¾çš„```
                    processed_response = processed_response.replace("```markdown", "", 1)
                    if processed_response.endswith("```"):
                        processed_response = processed_response[:-3]
                # ä» full_response ä¸­æå–åˆ†æç»“æœ
                return {
                    "status": "success",
                    "simplifier_result": processed_response
                }
                    
        except Exception as e:
            logger.error(f"simplifier_result processing error: {str(e)}")
            return {
                "status": "error",
                "message": str(e)
            }

class BrainstormingAgent:
    def __init__(self, api_key: str, prompt_templates: PromptTemplates):

        self.content_llm = ChatOpenAI(
            temperature=0.1,
            model=st.session_state.content_model,  # ä½¿ç”¨session stateä¸­çš„æ¨¡å‹
            api_key=api_key,
            base_url="https://openrouter.ai/api/v1",
            streaming=True
        )
        self.prompt_templates = prompt_templates
        self.setup_chains()

    def setup_chains(self):        # å†…å®¹è§„åˆ’ Chain 
        creator_prompt = ChatPromptTemplate.from_messages([
            ("system", f"{self.prompt_templates.get_template('consultant_role2')}\n\n"
                      f"ä»»åŠ¡:\n{self.prompt_templates.get_template('consultant_task2')}\n\n"
                      f"è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡º:\n{self.prompt_templates.get_template('output_format2')}"),
            ("human", "åŸºäºç´ æè¡¨document_content_simpleï¼š\n{document_content_simple}\n\n"
                     "æˆç»©å•transcript_analysisï¼š\n{transcript_analysis}\n\n"
                     "ç”³è¯·æ–¹å‘school_planï¼š\n{school_plan}\n\n"
                     "å®šåˆ¶éœ€æ±‚custom_requirementsï¼š\n{custom_requirements}\n\n"
                     "è¯·åˆ›å»ºè¯¦ç»†çš„å†…å®¹è§„åˆ’ã€‚")
        ])
        
        self.creator_chain = LLMChain(
            llm=self.content_llm,
            prompt=creator_prompt,
            output_key="creator_output",
            verbose=True
        )

    def process_creator(self, document_content_simple: str, school_plan: str, transcript_analysis: str = "æ— æˆç»©å•", custom_requirements: str = "æ— å®šåˆ¶éœ€æ±‚") -> Dict[str, Any]:
        try:
            # åˆ›å»ºä¸€ä¸ªé˜Ÿåˆ—ç”¨äºæµå¼è¾“å‡º
            message_queue = Queue()
            
            # åˆ›å»ºè‡ªå®šä¹‰å›è°ƒå¤„ç†å™¨ï¼Œç»§æ‰¿è‡ª BaseCallbackHandler
            class QueueCallbackHandler(BaseCallbackHandler):
                def __init__(self, queue):
                    self.queue = queue
                    super().__init__()
                
                def on_llm_new_token(self, token: str, **kwargs) -> None:
                    self.queue.put(token)
            
            # åˆ›å»ºä¸€ä¸ªç”Ÿæˆå™¨å‡½æ•°ï¼Œç”¨äºæµå¼è¾“å‡º
            def token_generator():
                while True:
                    try:
                        token = message_queue.get(block=False)
                        yield token
                    except Empty:
                        if not thread.is_alive() and message_queue.empty():
                            break
                    time.sleep(0.01)
            
            # åœ¨å•ç‹¬çš„çº¿ç¨‹ä¸­è¿è¡ŒLLM
            def run_llm():
                try:
                    result = self.creator_chain(
                        {
                            "document_content_simple": document_content_simple,  # æ·»åŠ æ–‡æ¡£å†…å®¹
                            "school_plan": school_plan,
                            "transcript_analysis": transcript_analysis,
                            "custom_requirements": custom_requirements
                        },
                        callbacks=[QueueCallbackHandler(message_queue)]
                    )
                    # å°†ç»“æœå­˜å‚¨åœ¨é˜Ÿåˆ—ä¸­
                    message_queue.put("\n\nè§„åˆ’å®Œæˆï¼")
                    return result
                except Exception as e:
                    message_queue.put(f"\n\né”™è¯¯: {str(e)}")
                    logger.error(f"Creator processing error: {str(e)}")
                    raise e
            
            # å¯åŠ¨çº¿ç¨‹
            thread = Thread(target=run_llm)
            thread.start()
            
            # åˆ›å»ºæµå¼è¾“å‡ºå®¹å™¨
            output_container = st.empty()
            
            # æµå¼è¾“å‡º
            with output_container:
                full_response = st.write_stream(token_generator())
            
            # ç­‰å¾…çº¿ç¨‹å®Œæˆ
            thread.join()
            # æ¸…ç©ºåŸå®¹å™¨å¹¶ä½¿ç”¨markdowné‡æ–°æ¸²æŸ“å®Œæ•´å“åº”
            if full_response:
                # å¤„ç†å¯èƒ½å­˜åœ¨çš„markdownä»£ç å—æ ‡è®°
                if full_response.startswith("```markdown"):
                    # ç§»é™¤å¼€å¤´çš„```markdownå’Œç»“å°¾çš„```
                    full_response = full_response.replace("```markdown", "", 1)
                    if full_response.endswith("```"):
                        full_response = full_response[:-3]
                
                output_container.empty()
                new_container = st.container()
                with new_container:
                    st.markdown(full_response)
            # è·å–ç»“æœ
            if hasattr(thread, "_exception") and thread._exception:
                raise thread._exception
            
            logger.info("Creator analysis completed successfully")
            processed_response = full_response
            if processed_response.startswith("```markdown"):
                # ç§»é™¤å¼€å¤´çš„```markdownå’Œç»“å°¾çš„```
                processed_response = processed_response.replace("```markdown", "", 1)
                if processed_response.endswith("```"):
                    processed_response = processed_response[:-3]

            return {
                "status": "success",
                "creator_output": processed_response
            }
                
        except Exception as e:
            logger.error(f"Creator processing error: {str(e)}")
            return {
                "status": "error",
                "message": str(e)
            }


def add_custom_css():
    st.markdown("""
    <style>
    /* æ•´ä½“é¡µé¢æ ·å¼ */
    .main {
        padding: 2rem;
    }
    
    /* æ ‡é¢˜æ ·å¼ */
    h1, h2, h3 {
        color: #1e3a8a;
        font-weight: 600;
        margin-bottom: 1.5rem;
    }
    
    .page-title {
        text-align: center;
        font-size: 2.5rem;
        margin-bottom: 2rem;
        color: #1e3a8a;
        font-weight: bold;
        padding: 1rem;
        border-bottom: 3px solid #e5e7eb;
    }
    
    /* æ–‡ä»¶ä¸Šä¼ åŒºåŸŸæ ·å¼ */
    .stFileUploader {
        margin-bottom: 2rem;
    }
    
    .stFileUploader > div > button {
        background-color: #f8fafc;
        color: #1e3a8a;
        border: 2px dashed #1e3a8a;
        border-radius: 8px;
        padding: 1rem;
        transition: all 0.3s ease;
    }
    
    .stFileUploader > div > button:hover {
        background-color: #f0f7ff;
        border-color: #2563eb;
    }
    
    /* æŒ‰é’®æ ·å¼ */
    .stButton > button {
        background-color: #1e3a8a;
        color: white;
        border-radius: 8px;
        padding: 0.75rem 1.5rem;
        font-weight: 500;
        border: none;
        width: 100%;
        transition: all 0.3s ease;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    
    .stButton > button:hover {
        background-color: #2563eb;
        transform: translateY(-1px);
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
    
    .stButton > button:disabled {
        background-color: #94a3b8;
        cursor: not-allowed;
    }
    
    /* æ–‡æœ¬åŒºåŸŸæ ·å¼ */
    .stTextArea > div > div > textarea {
        border-radius: 8px;
        border: 1px solid #e2e8f0;
        padding: 0.75rem;
        font-size: 1rem;
        transition: all 0.3s ease;
    }
    
    .stTextArea > div > div > textarea:focus {
        border-color: #2563eb;
        box-shadow: 0 0 0 3px rgba(37,99,235,0.1);
    }
    
    /* åˆ†æç»“æœåŒºåŸŸæ ·å¼ */
    .analysis-container {
        background-color: white;
        border-radius: 12px;
        padding: 1.5rem;
        margin: 1rem 0;
        box-shadow: 0 4px 6px rgba(0,0,0,0.05);
        border: 1px solid #e5e7eb;
    }
    
    /* æˆåŠŸæ¶ˆæ¯æ ·å¼ */
    .stSuccess {
        background-color: #ecfdf5;
        color: #065f46;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #059669;
        margin: 1rem 0;
    }
    
    /* é”™è¯¯æ¶ˆæ¯æ ·å¼ */
    .stError {
        background-color: #fef2f2;
        color: #991b1b;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #dc2626;
        margin: 1rem 0;
    }
    
    /* æ¨¡å‹ä¿¡æ¯æ ·å¼ */
    .model-info {
        background-color: #f0f7ff;
        padding: 0.75rem 1rem;
        border-radius: 8px;
        margin: 0.5rem 0;
        display: inline-block;
        font-size: 0.9rem;
        border: 1px solid #bfdbfe;
    }
    
    /* åŒåˆ—å¸ƒå±€æ ·å¼ */
    .dual-column {
        display: flex;
        gap: 2rem;
        margin: 1rem 0;
    }
    
    .column {
        flex: 1;
        background-color: #f8fafc;
        padding: 1.5rem;
        border-radius: 12px;
        border: 1px solid #e5e7eb;
    }
    
    /* åˆ†éš”çº¿æ ·å¼ */
    hr {
        margin: 2rem 0;
        border: 0;
        height: 1px;
        background: linear-gradient(to right, transparent, #e5e7eb, transparent);
    }
    
    /* æ ‡ç­¾é¡µæ ·å¼ */
    .stTabs {
        background-color: white;
        border-radius: 12px;
        padding: 1rem;
        box-shadow: 0 1px 3px rgba(0,0,0,0.1);
    }
    
    .stTab {
        padding: 1rem;
    }
    
    /* å±•å¼€å™¨æ ·å¼ */
    .streamlit-expanderHeader {
        background-color: #f8fafc;
        border-radius: 8px;
        padding: 0.75rem;
        font-weight: 500;
        color: #1e3a8a;
        border: 1px solid #e5e7eb;
    }
    
    .streamlit-expanderContent {
        background-color: white;
        border-radius: 0 0 8px 8px;
        padding: 1rem;
        border: 1px solid #e5e7eb;
        border-top: none;
    }
    
    /* åŠ è½½åŠ¨ç”»æ ·å¼ */
    .stSpinner > div {
        border-color: #2563eb transparent transparent transparent;
    }
    
    /* æ–‡æ¡£åˆ†æåŒºåŸŸæ ·å¼ */
    .doc-analysis-area {
        background-color: #ffffff;
        border-radius: 12px;
        padding: 1.5rem;
        margin: 1rem 0;
        box-shadow: 0 2px 4px rgba(0,0,0,0.05);
        border: 1px solid #e5e7eb;
    }
    
    .doc-analysis-area h3 {
        color: #1e3a8a;
        font-size: 1.25rem;
        margin-bottom: 1rem;
        padding-bottom: 0.5rem;
        border-bottom: 2px solid #e5e7eb;
    }
    
    /* è°ƒæ•´åˆ—å®½åº¦ */
    .column-adjust {
        padding: 0 1rem;
    }
    </style>
    """, unsafe_allow_html=True)


def initialize_session_state():
    if 'templates' not in st.session_state:
        prompt_templates = PromptTemplates()
        st.session_state.templates = prompt_templates.default_templates.copy()
    
    if 'prompt_templates' not in st.session_state:
        st.session_state.prompt_templates = PromptTemplates()
    
    # åˆå§‹åŒ–å­¦æ ¡ç ”ç©¶æ¨¡å‹
    if 'school_research_model' not in st.session_state:
        st.session_state.school_research_model = "google/gemini-2.0-flash-001"
    
    # åˆå§‹åŒ–æ”¯æŒæ–‡ä»¶åˆ†ææ¨¡å‹
    if 'support_analysis_model' not in st.session_state:
        st.session_state.support_analysis_model = "qwen/qwen-max"
    
    # åˆå§‹åŒ–PSç­–ç•¥æ¨¡å‹
    if 'ps_strategy_model' not in st.session_state:
        st.session_state.ps_strategy_model = "qwen/qwen-max"
    
    # åˆå§‹åŒ–å†…å®¹åˆ›ä½œæ¨¡å‹
    if 'content_creation_model' not in st.session_state:
        st.session_state.content_creation_model = "qwen/qwen-max"
    
    # åˆå§‹åŒ–æˆç»©å•åˆ†ææ¨¡å‹
    if 'transcript_model' not in st.session_state:
        st.session_state.transcript_model = "qwen/qwen-max"
    
    # åˆå§‹åŒ–ç®€åŒ–å™¨æ¨¡å‹
    if 'simplifier_model' not in st.session_state:
        st.session_state.simplifier_model = "qwen/qwen-max"
        
    # åˆå§‹åŒ–å†…å®¹æ¨¡å‹
    if 'content_model' not in st.session_state:
        st.session_state.content_model = "qwen/qwen-max"
    
    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€å˜é‡
    if 'school_name' not in st.session_state:
        st.session_state.school_name = ""
    
    if 'program_name' not in st.session_state:
        st.session_state.program_name = ""
    
    if 'research_result' not in st.session_state:
        st.session_state.research_result = None
    
    if 'research_done' not in st.session_state:
        st.session_state.research_done = False
    
    if 'ps_draft' not in st.session_state:
        st.session_state.ps_draft = None
    
    if 'support_file' not in st.session_state:
        st.session_state.support_file = None
    
    if 'support_analysis_result' not in st.session_state:
        st.session_state.support_analysis_result = None
    
    if 'support_analysis_done' not in st.session_state:
        st.session_state.support_analysis_done = False
    
    if 'ps_strategy_result' not in st.session_state:
        st.session_state.ps_strategy_result = None
    
    if 'ps_strategy_done' not in st.session_state:
        st.session_state.ps_strategy_done = False
    
    if 'content_creation_result' not in st.session_state:
        st.session_state.content_creation_result = None
    
    if 'content_creation_done' not in st.session_state:
        st.session_state.content_creation_done = False
    
    if 'show_research' not in st.session_state:
        st.session_state.show_research = False
    
    if 'show_support_analysis' not in st.session_state:
        st.session_state.show_support_analysis = False
    
    if 'show_ps_strategy' not in st.session_state:
        st.session_state.show_ps_strategy = False
    
    if 'show_content_creation' not in st.session_state:
        st.session_state.show_content_creation = False
    
    # åŸæœ‰çš„çŠ¶æ€å˜é‡
    if 'document_content' not in st.session_state:
        st.session_state.document_content = None
    if 'transcript_file' not in st.session_state:
        st.session_state.transcript_file = None
    if 'transcript_analysis_done' not in st.session_state:
        st.session_state.transcript_analysis_done = False
    if 'transcript_analysis_result' not in st.session_state:
        st.session_state.transcript_analysis_result = None
    if 'strategist_analysis_done' not in st.session_state:
        st.session_state.strategist_analysis_done = False
    if 'strategist_analysis_result' not in st.session_state:
        st.session_state.strategist_analysis_result = None
    if 'creator_analysis_done' not in st.session_state:
        st.session_state.creator_analysis_done = False
    if 'creator_analysis_result' not in st.session_state:
        st.session_state.creator_analysis_result = None
    if 'show_transcript_analysis' not in st.session_state:
        st.session_state.show_transcript_analysis = False
    if 'show_strategist_analysis' not in st.session_state:
        st.session_state.show_strategist_analysis = False
    if 'show_creator_analysis' not in st.session_state:
        st.session_state.show_creator_analysis = False
    if 'show_simplifier_analysis' not in st.session_state:
        st.session_state.show_simplifier_analysis = False
    if 'simplifier_analysis_done' not in st.session_state:
        st.session_state.simplifier_analysis_done = False
    if 'simplifier_result' not in st.session_state:
        st.session_state.simplifier_result = None

def main():
    """ä¸»åº”ç”¨ç¨‹åºå…¥å£ç‚¹"""
    # åˆå§‹åŒ–çŠ¶æ€
    if "generated_ps" not in st.session_state:
        st.session_state.generated_ps = ""
    
    # è®¾ç½®é¡µé¢æ ‡é¢˜
    st.title("ğŸ“ PSåŠ©æ‰‹å¹³å°")
    
    # æ˜¾ç¤ºMCPçŠ¶æ€æŒ‡ç¤ºå™¨
    render_status_indicator()
    
    # ç®€å•æ˜¾ç¤ºä¸€äº›æ–‡æœ¬
    st.write("åº”ç”¨ç¨‹åºå·²æˆåŠŸå¯åŠ¨ï¼")
    st.info("MCPè¿æ¥æµ‹è¯•ï¼šä½¿ç”¨æµ‹è¯•è„šæœ¬ `python test_mcp_setup.py` å¯ä»¥è¯Šæ–­MCPè¿æ¥é—®é¢˜")
    
    # æ˜¾ç¤ºä¸€ä¸ªå ä½ç¬¦
    st.write("è¯·ä½¿ç”¨ä¾§è¾¹æ é…ç½®åº”ç”¨ç¨‹åºé€‰é¡¹")
    
    # å¯é€‰ï¼šæ·»åŠ ä¾§è¾¹æ å†…å®¹
    st.sidebar.title("é…ç½®é€‰é¡¹")
    st.sidebar.write("åº”ç”¨ç¨‹åºé…ç½®é€‰é¡¹å°†æ˜¾ç¤ºåœ¨è¿™é‡Œ")

class SchoolResearchAgent:
    def __init__(self, api_key: str, serper_api_key: str, smithery_api_key: str, prompt_templates: PromptTemplates):
        self.prompt_templates = prompt_templates
        self.smithery_api_key = smithery_api_key
        self.serper_api_key = serper_api_key
        self.openrouter_api_key = api_key  # å­˜å‚¨ OpenRouter API å¯†é’¥ä»¥ä¾›å›é€€æ–¹æ¡ˆä½¿ç”¨
        
        self.llm = ChatOpenAI(
            temperature=0.1,
            model=st.session_state.school_research_model,  # ä½¿ç”¨session stateä¸­çš„æ¨¡å‹
            api_key=api_key,
            base_url="https://openrouter.ai/api/v1",
            streaming=True
        )
        
        # è®¾ç½®Serperæœç´¢å·¥å…·
        self.serper_tool = SerperSearchResults(
            serper_api_key=serper_api_key
        )
        
        # è®¾ç½®SearchSchoolInfoç³»ç»Ÿæç¤º
        self.setup_chains()
        
    def setup_chains(self):
        # åˆ›å»ºå­¦æ ¡ç ”ç©¶çš„Chain
        research_prompt = ChatPromptTemplate.from_messages([
            ("system", f"{self.prompt_templates.get_template('school_research_role')}\n\n"
                     f"ä»»åŠ¡:\n{self.prompt_templates.get_template('school_research_task')}\n\n"
                     f"è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡º:\n{self.prompt_templates.get_template('school_research_output')}"),
            ("human", "è¯·ç ”ç©¶ä»¥ä¸‹å­¦æ ¡å’Œä¸“ä¸šï¼š\nå­¦æ ¡åç§°ï¼š{school_name}\nä¸“ä¸šåç§°ï¼š{program_name}")
        ])
        
        self.research_chain = LLMChain(
            llm=self.llm,
            prompt=research_prompt,
            output_key="research_result",
            verbose=True
        )
    
    async def run_mcp_thinking(self, task, callback_handler=None):
        """ä½¿ç”¨Smithery MCPè¿›è¡Œç»“æ„åŒ–æ€è€ƒçš„å¼‚æ­¥æ–¹æ³•"""
        # æ£€æŸ¥MCPæ˜¯å¦å¯ç”¨
        if not MCP_AVAILABLE:
            logger.warning("MCPä¸å¯ç”¨ï¼Œä½¿ç”¨æ›¿ä»£å®ç°")
            try:
                # ä½¿ç”¨æ›¿ä»£å®ç°
                from mcp_fallback import run_sequential_thinking
                logger.info("ä½¿ç”¨mcp_fallback.run_sequential_thinkingæ›¿ä»£å®ç°")
                result = await run_sequential_thinking(
                    task, 
                    self.smithery_api_key, 
                    callback=lambda token: callback_handler.on_llm_new_token(token, **{}) if callback_handler else None
                )
                return result
            except Exception as e:
                logger.error(f"æ›¿ä»£å®ç°é”™è¯¯: {str(e)}")
                if callback_handler:
                    callback_handler.on_llm_new_token(f"æ›¿ä»£å®ç°é”™è¯¯: {str(e)}\nä½¿ç”¨ç›´æ¥LLMè°ƒç”¨...\n", **{})
                
                # ä½¿ç”¨ LLM ç›´æ¥å¤„ç†ä»»åŠ¡
                messages = [
                    SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é™¢æ ¡ç ”ç©¶åŠ©æ‰‹ï¼Œæ“…é•¿åˆ†æå„å›½å¤§å­¦çš„ä¸“ä¸šé¡¹ç›®ä¿¡æ¯ã€‚"),
                    HumanMessage(content=task)
                ]
                
                chat = ChatOpenAI(
                    temperature=0.1,
                    model="anthropic/claude-3-haiku-20240307",
                    api_key=self.openrouter_api_key,
                    base_url="https://openrouter.ai/api/v1",
                    streaming=True
                )
                
                response = chat.invoke(
                    messages,
                    callbacks=[callback_handler] if callback_handler else None
                )
                
                return response.content
        
        logger.info("ä½¿ç”¨MCPè¿›è¡Œç»“æ„åŒ–æ€è€ƒ")
        
        # é…ç½®ä¿¡æ¯
        config = {
            "serperApiKey": self.serper_api_key
        }
        # ç¼–ç é…ç½®ä¸ºbase64
        config_b64 = base64.b64encode(json.dumps(config).encode()).decode()
        
        # åˆ›å»ºæœåŠ¡å™¨URL
        url = f"https://server.smithery.ai/@marcopesani/mcp-server-sequential-thinking/mcp?config={config_b64}&api_key={self.smithery_api_key}"
        logger.info(f"è¿æ¥åˆ°SmitheryæœåŠ¡å™¨: {url[:70]}...")
        
        result = ""
        try:
            # ä½¿ç”¨mcp.create_clientè¿æ¥
            logger.info("åˆ›å»ºMCPå®¢æˆ·ç«¯...")
            client_session = await mcp.create_client(url)
            logger.info("MCPå®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ")
            
            try:
                # åˆ—å‡ºå¯ç”¨å·¥å…·
                logger.info("è·å–å¯ç”¨å·¥å…·...")
                tools = await client_session.list_tools()
                logger.info(f"å¯ç”¨å·¥å…·: {', '.join([t.name for t in tools.tools])}")
                
                # æ‰§è¡Œæ€è€ƒä»»åŠ¡
                logger.info("æ‰§è¡Œsequential-thinkingå·¥å…·...")
                thinking_result = await client_session.run_tool(
                    "sequential-thinking",
                    {
                        "task": task
                    }
                )
                logger.info("sequential-thinkingæ‰§è¡Œå®Œæˆ")
                result = thinking_result
                
                if callback_handler:
                    # å°†ç»“æœå‘é€åˆ°å›è°ƒå¤„ç†å™¨ä»¥æµå¼æ˜¾ç¤º
                    for token in str(result).split():  # ç®€å•æ‹†åˆ†ä¸ºè¯ä½œä¸ºtoken
                        callback_handler.on_llm_new_token(token + " ", **{})
                
                # å…³é—­ä¼šè¯
                await client_session.close()
            except Exception as api_error:
                logger.error(f"MCP APIè°ƒç”¨å¤±è´¥: {str(api_error)}")
                try:
                    await client_session.close()
                except:
                    pass
                raise api_error
        except Exception as e:
            logger.error(f"MCPæœåŠ¡è°ƒç”¨å¤±è´¥: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())
            if callback_handler:
                callback_handler.on_llm_new_token(f"MCPæœåŠ¡è°ƒç”¨å¤±è´¥: {str(e)}\nä½¿ç”¨å¤‡ç”¨æ–¹æ³•...\n", **{})
            
            try:
                # ä½¿ç”¨æ›¿ä»£å®ç°
                from mcp_fallback import run_sequential_thinking
                result = await run_sequential_thinking(
                    task, 
                    self.smithery_api_key, 
                    callback=lambda token: callback_handler.on_llm_new_token(token, **{}) if callback_handler else None
                )
            except Exception as fallback_error:
                logger.error(f"æ›¿ä»£å®ç°é”™è¯¯: {str(fallback_error)}")
                if callback_handler:
                    callback_handler.on_llm_new_token(f"æ›¿ä»£å®ç°é”™è¯¯: {str(fallback_error)}\nä½¿ç”¨ç›´æ¥LLMè°ƒç”¨...\n", **{})
                
                # ä½¿ç”¨ LLM ç›´æ¥å¤„ç†ä»»åŠ¡
                messages = [
                    SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é™¢æ ¡ç ”ç©¶åŠ©æ‰‹ï¼Œæ“…é•¿åˆ†æå„å›½å¤§å­¦çš„ä¸“ä¸šé¡¹ç›®ä¿¡æ¯ã€‚"),
                    HumanMessage(content=task)
                ]
                
                chat = ChatOpenAI(
                    temperature=0.1,
                    model="anthropic/claude-3-haiku-20240307",
                    api_key=self.openrouter_api_key,
                    base_url="https://openrouter.ai/api/v1",
                    streaming=True
                )
                
                response = chat.invoke(
                    messages,
                    callbacks=[callback_handler] if callback_handler else None
                )
                
                result = response.content
                
        return result
    
    def process_school_research(self, school_name: str, program_name: str) -> Dict[str, Any]:
        try:
            # åˆ›å»ºä¸€ä¸ªé˜Ÿåˆ—ç”¨äºæµå¼è¾“å‡º
            message_queue = Queue()
            
            # åˆ›å»ºè‡ªå®šä¹‰å›è°ƒå¤„ç†å™¨
            class QueueCallbackHandler(BaseCallbackHandler):
                def __init__(self, queue):
                    self.queue = queue
                    super().__init__()
                
                def on_llm_new_token(self, token: str, **kwargs) -> None:
                    self.queue.put(token)
            
            # åˆ›å»ºä¸€ä¸ªç”Ÿæˆå™¨å‡½æ•°ï¼Œç”¨äºæµå¼è¾“å‡º
            def token_generator():
                while True:
                    try:
                        token = message_queue.get(block=False)
                        yield token
                    except Empty:
                        if not thread.is_alive() and message_queue.empty():
                            break
                    time.sleep(0.01)
            
            # åœ¨å•ç‹¬çš„çº¿ç¨‹ä¸­è¿è¡Œè°ƒæŸ¥
            def run_research():
                try:
                    # é¦–å…ˆæ‰§è¡Œæœç´¢æŸ¥è¯¢
                    search_queries = [
                        f"{school_name} {program_name} program description curriculum",
                        f"{school_name} {program_name} admission requirements",
                        f"{school_name} {program_name} research areas faculty",
                        f"{school_name} {program_name} career prospects alumni"
                    ]
                    
                    all_search_results = []
                    message_queue.put("æ­£åœ¨è¿›è¡Œç½‘ç»œæœç´¢...\n\n")
                    
                    for query in search_queries:
                        try:
                            message_queue.put(f"æœç´¢: {query}\n")
                            result = self.serper_tool.search(query)
                            all_search_results.append(result)
                            message_queue.put("âœ“ æœç´¢å®Œæˆ\n")
                        except Exception as e:
                            message_queue.put(f"Ã— æœç´¢å¤±è´¥: {str(e)}\n")
                    
                    message_queue.put("\næ­£åœ¨åˆ†ææœç´¢ç»“æœå¹¶ç”ŸæˆæŠ¥å‘Š...\n\n")
                    
                    # æ•´åˆæœç´¢ç»“æœ
                    combined_search_results = "\n\n".join([json.dumps(result) for result in all_search_results])
                    
                    try:
                        # ä½¿ç”¨æ€è€ƒé“¾è¿›è¡Œç³»ç»Ÿçš„ä¿¡æ¯æ•´åˆ
                        callback_handler = QueueCallbackHandler(message_queue)
                        # ä½¿ç”¨asyncioè¿è¡Œå¼‚æ­¥MCPå‡½æ•°
                        thinking_result = asyncio.run(self.run_mcp_thinking(
                            f"åˆ†æ{school_name}çš„{program_name}ä¸“ä¸šä¿¡æ¯ï¼Œå¹¶æŒ‰æ ¼å¼ç»„ç»‡æˆé™¢æ ¡ä¿¡æ¯æ±‡æ€»æŠ¥å‘Šï¼ŒåŸºäºä»¥ä¸‹æœç´¢ç»“æœï¼š\n\n{combined_search_results}",
                            callback_handler
                        ))
                        message_queue.put("\n\næ€è€ƒåˆ†æå®Œæˆï¼Œæ­£åœ¨ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š...\n\n")
                    except Exception as e:
                        logger.error(f"ç»“æ„åŒ–æ€è€ƒè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
                        message_queue.put(f"\n\nç»“æ„åŒ–æ€è€ƒè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}\nè·³è¿‡ç»“æ„åŒ–æ€è€ƒé˜¶æ®µï¼Œç›´æ¥ç”ŸæˆæŠ¥å‘Š...\n\n")
                        thinking_result = ""
                    
                    # ä¼ é€’ç»“æœåˆ°ç ”ç©¶é“¾
                    result = self.research_chain(
                        {
                            "school_name": school_name,
                            "program_name": program_name,
                            "search_results": combined_search_results
                        },
                        callbacks=[QueueCallbackHandler(message_queue)]
                    )
                    
                    message_queue.put("\n\né™¢æ ¡ä¿¡æ¯æ±‡æ€»æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
                    thread.result = result["research_result"]
                    return result
                    
                except Exception as e:
                    message_queue.put(f"\n\né”™è¯¯: {str(e)}")
                    logger.error(f"å­¦æ ¡ç ”ç©¶é”™è¯¯: {str(e)}")
                    thread.exception = e
                    raise e
            
            # å¯åŠ¨çº¿ç¨‹
            thread = Thread(target=run_research)
            thread.start()
            
            # ç”¨äºæµå¼è¾“å‡ºçš„å®¹å™¨
            output_container = st.empty()
            
            # æµå¼è¾“å‡º
            with output_container:
                full_response = st.write_stream(token_generator())
            
            # ç­‰å¾…çº¿ç¨‹å®Œæˆ
            thread.join()
            
            # æ¸…ç©ºåŸå®¹å™¨å¹¶ä½¿ç”¨markdowné‡æ–°æ¸²æŸ“å®Œæ•´å“åº”
            if hasattr(thread, "result"):
                output_container.empty()
                output_container.markdown(thread.result)
            
            # è·å–ç»“æœ
            if hasattr(thread, "exception") and thread.exception:
                raise thread.exception
            
            logger.info("å­¦æ ¡ç ”ç©¶å®Œæˆ")
            
            return {
                "status": "success",
                "research_result": thread.result if hasattr(thread, "result") else full_response
            }
                
        except Exception as e:
            logger.error(f"å­¦æ ¡ç ”ç©¶é”™è¯¯: {str(e)}")
            return {
                "status": "error",
                "message": str(e)
            }

class SupportFileAnalyzer:
    def __init__(self, api_key: str, prompt_templates: PromptTemplates):
        self.prompt_templates = prompt_templates
            
        self.llm = ChatOpenAI(
            temperature=0.1,
            model=st.session_state.support_analysis_model,  # ä½¿ç”¨session stateä¸­çš„æ¨¡å‹
            api_key=api_key,
            base_url="https://openrouter.ai/api/v1",
            streaming=True
        )
        
        self.setup_chains()
    
    def extract_images_from_pdf(self, pdf_bytes):
        """ä»PDFä¸­æå–å›¾åƒ"""
        try:
            images = []
            pdf_document = fitz.open(stream=pdf_bytes, filetype="pdf")
            
            for page_num in range(len(pdf_document)):
                page = pdf_document[page_num]
                # å°†é¡µé¢ç›´æ¥è½¬æ¢ä¸ºå›¾åƒ
                pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))
                img_bytes = pix.tobytes("png")
                # å°†å›¾åƒç¼–ç ä¸ºbase64å­—ç¬¦ä¸²
                img_base64 = base64.b64encode(img_bytes).decode('utf-8')
                images.append(img_base64)
            
            return images
        except Exception as e:
            logger.error(f"æå–PDFå›¾åƒæ—¶å‡ºé”™: {str(e)}")
            return []
    
    def setup_chains(self):
        # åˆ›å»ºæ”¯æŒæ–‡ä»¶åˆ†æçš„Chain
        analysis_prompt = ChatPromptTemplate.from_messages([
            ("system", f"{self.prompt_templates.get_template('support_analysis_role')}\n\n"
                     f"ä»»åŠ¡:\n{self.prompt_templates.get_template('support_analysis_task')}\n\n"
                     f"è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡º:\n{self.prompt_templates.get_template('support_analysis_output')}"),
            ("human", "è¯·åˆ†æä¸Šä¼ çš„æ”¯æŒæ–‡ä»¶ï¼š\n{file_content}\n\nç›®æ ‡å­¦æ ¡å’Œä¸“ä¸šï¼š\nå­¦æ ¡ï¼š{school_name}\nä¸“ä¸šï¼š{program_name}")
        ])
        
        self.analysis_chain = LLMChain(
            llm=self.llm,
            prompt=analysis_prompt,
            output_key="support_analysis_result",
            verbose=True
        )
    
    def analyze_file(self, file_bytes, file_name, file_type, school_name, program_name) -> Dict[str, Any]:
        try:
            # åˆ›å»ºä¸€ä¸ªé˜Ÿåˆ—ç”¨äºæµå¼è¾“å‡º
            message_queue = Queue()
            
            # åˆ›å»ºè‡ªå®šä¹‰å›è°ƒå¤„ç†å™¨
            class QueueCallbackHandler(BaseCallbackHandler):
                def __init__(self, queue):
                    self.queue = queue
                    super().__init__()
                
                def on_llm_new_token(self, token: str, **kwargs) -> None:
                    self.queue.put(token)
            
            # åˆ›å»ºä¸€ä¸ªç”Ÿæˆå™¨å‡½æ•°ï¼Œç”¨äºæµå¼è¾“å‡º
            def token_generator():
                while True:
                    try:
                        token = message_queue.get(block=False)
                        yield token
                    except Empty:
                        if not thread.is_alive() and message_queue.empty():
                            break
                    time.sleep(0.01)
            
            # åœ¨å•ç‹¬çš„çº¿ç¨‹ä¸­è¿è¡Œåˆ†æ
            def run_analysis():
                try:
                    file_content = ""
                    
                    # æ ¹æ®æ–‡ä»¶ç±»å‹å¤„ç†æ–‡ä»¶å†…å®¹
                    if file_type == "pdf":
                        # æå–PDFæ–‡æœ¬
                        pdf_reader = PdfReader(io.BytesIO(file_bytes))
                        text_content = ""
                        for page in pdf_reader.pages:
                            text_content += page.extract_text() + "\n"
                        
                        # å¦‚æœæ–‡æœ¬å†…å®¹å¤ªå°‘ï¼Œå¯èƒ½æ˜¯æ‰«æçš„PDFï¼Œæå–å›¾åƒ
                        if len(text_content.strip()) < 100:
                            images = self.extract_images_from_pdf(file_bytes)
                            if images:
                                # ä½¿ç”¨å›¾åƒè¿›è¡Œåˆ†æ
                                message_queue.put("æ–‡ä»¶ä¼¼ä¹æ˜¯æ‰«æç‰ˆPDFï¼Œæ­£åœ¨ä½¿ç”¨å›¾åƒè¯†åˆ«è¿›è¡Œåˆ†æ...\n")
                                
                                messages = [
                                    SystemMessage(content=f"{self.prompt_templates.get_template('support_analysis_role')}\n\n"
                                                         f"ä»»åŠ¡:\n{self.prompt_templates.get_template('support_analysis_task')}"),
                                    HumanMessage(content=[  # æ³¨æ„è¿™é‡Œæ”¹æˆäº†åˆ—è¡¨
                                        {
                                            "type": "text",
                                            "text": f"è¯·åˆ†æè¿™ä»½æ”¯æŒæ–‡ä»¶ï¼Œæå–å…³é”®ä¿¡æ¯ã€‚ç›®æ ‡å­¦æ ¡ï¼š{school_name}ï¼Œç›®æ ‡ä¸“ä¸šï¼š{program_name}"
                                        },
                                        {
                                            "type": "image_url",
                                            "image_url": {
                                                "url": f"data:image/png;base64,{images[0]}"
                                            }
                                        }
                                    ])
                                ]
                                
                                result = self.llm.invoke(
                                    messages,
                                    callbacks=[QueueCallbackHandler(message_queue)]
                                )
                                thread.result = result.content
                                return {"support_analysis_result": result.content}
                        else:
                            file_content = text_content
                    
                    elif file_type == "docx":
                        # å¤„ç†Wordæ–‡æ¡£
                        try:
                            file_stream = io.BytesIO(file_bytes)
                            md = MarkItDown()
                            file_content = md.convert(file_stream)
                        except Exception as e:
                            doc = Document(io.BytesIO(file_bytes))
                            full_text = []
                            for para in doc.paragraphs:
                                full_text.append(para.text)
                            file_content = '\n'.join(full_text)
                    
                    elif file_type == "image":
                        # å¤„ç†å›¾åƒæ–‡ä»¶
                        message_queue.put("æ­£åœ¨åˆ†æå›¾åƒæ–‡ä»¶...\n")
                        
                        image_base64 = base64.b64encode(file_bytes).decode('utf-8')
                        
                        messages = [
                            SystemMessage(content=f"{self.prompt_templates.get_template('support_analysis_role')}\n\n"
                                                 f"ä»»åŠ¡:\n{self.prompt_templates.get_template('support_analysis_task')}"),
                            HumanMessage(content=[  # æ³¨æ„è¿™é‡Œæ”¹æˆäº†åˆ—è¡¨
                                {
                                    "type": "text",
                                    "text": f"è¯·åˆ†æè¿™ä»½æ”¯æŒæ–‡ä»¶ï¼Œæå–å…³é”®ä¿¡æ¯ã€‚ç›®æ ‡å­¦æ ¡ï¼š{school_name}ï¼Œç›®æ ‡ä¸“ä¸šï¼š{program_name}"
                                },
                                {
                                    "type": "image_url",
                                    "image_url": {
                                        "url": f"data:image/png;base64,{image_base64}"
                                    }
                                }
                            ])
                        ]
                        
                        result = self.llm.invoke(
                            messages,
                            callbacks=[QueueCallbackHandler(message_queue)]
                        )
                        thread.result = result.content
                        return {"support_analysis_result": result.content}
                    
                    else:
                        file_content = "ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹"
                    
                    # å¯¹äºæ–‡æœ¬å†…å®¹ï¼Œä½¿ç”¨æ ‡å‡†çš„åˆ†æé“¾
                    if file_content:
                        result = self.analysis_chain(
                            {
                                "file_content": file_content,
                                "school_name": school_name,
                                "program_name": program_name
                            },
                            callbacks=[QueueCallbackHandler(message_queue)]
                        )
                        
                        thread.result = result["support_analysis_result"]
                        return result
                
                except Exception as e:
                    message_queue.put(f"\n\né”™è¯¯: {str(e)}")
                    logger.error(f"æ”¯æŒæ–‡ä»¶åˆ†æé”™è¯¯: {str(e)}")
                    thread.exception = e
                    raise e
            
            # å¯åŠ¨çº¿ç¨‹
            thread = Thread(target=run_analysis)
            thread.start()
            
            # ç”¨äºæµå¼è¾“å‡ºçš„å®¹å™¨
            output_container = st.empty()
            
            # æµå¼è¾“å‡º
            with output_container:
                full_response = st.write_stream(token_generator())
            
            # ç­‰å¾…çº¿ç¨‹å®Œæˆ
            thread.join()
            
            # æ¸…ç©ºåŸå®¹å™¨å¹¶ä½¿ç”¨markdowné‡æ–°æ¸²æŸ“å®Œæ•´å“åº”
            if hasattr(thread, "result"):
                output_container.empty()
                output_container.markdown(thread.result)
            
            # è·å–ç»“æœ
            if hasattr(thread, "exception") and thread.exception:
                raise thread.exception
            
            logger.info("æ”¯æŒæ–‡ä»¶åˆ†æå®Œæˆ")
            
            return {
                "status": "success",
                "support_analysis_result": thread.result if hasattr(thread, "result") else full_response
            }
                
        except Exception as e:
            logger.error(f"æ”¯æŒæ–‡ä»¶åˆ†æé”™è¯¯: {str(e)}")
            return {
                "status": "error",
                "message": str(e)
            }

class PSStrategyAgent:
    def __init__(self, api_key: str, prompt_templates: PromptTemplates):
        self.prompt_templates = prompt_templates
            
        self.llm = ChatOpenAI(
            temperature=0.1,
            model=st.session_state.ps_strategy_model,  # ä½¿ç”¨session stateä¸­çš„æ¨¡å‹
            api_key=api_key,
            base_url="https://openrouter.ai/api/v1",
            streaming=True
        )
        
        self.setup_chains()
    
    def setup_chains(self):
        # åˆ›å»ºPSç­–ç•¥çš„Chain
        strategy_prompt = ChatPromptTemplate.from_messages([
            ("system", f"{self.prompt_templates.get_template('ps_strategy_role')}\n\n"
                     f"ä»»åŠ¡:\n{self.prompt_templates.get_template('ps_strategy_task')}\n\n"
                     f"è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡º:\n{self.prompt_templates.get_template('ps_strategy_output')}"),
            ("human", "è¯·åŸºäºä»¥ä¸‹èµ„æ–™åˆ¶å®šPSæ”¹å†™ç­–ç•¥ï¼š\n\nPSåˆç¨¿å†…å®¹ï¼š\n{ps_draft}\n\næ”¯æŒæ–‡ä»¶åˆ†ææŠ¥å‘Šï¼š\n{support_analysis}\n\nç›®æ ‡å­¦æ ¡å’Œä¸“ä¸šï¼š\nå­¦æ ¡ï¼š{school_name}\nä¸“ä¸šï¼š{program_name}")
        ])
        
        self.strategy_chain = LLMChain(
            llm=self.llm,
            prompt=strategy_prompt,
            output_key="ps_strategy_result",
            verbose=True
        )
    
    def create_strategy(self, ps_draft: str, support_analysis: str, school_name: str, program_name: str) -> Dict[str, Any]:
        try:
            # åˆ›å»ºä¸€ä¸ªé˜Ÿåˆ—ç”¨äºæµå¼è¾“å‡º
            message_queue = Queue()
            
            # åˆ›å»ºè‡ªå®šä¹‰å›è°ƒå¤„ç†å™¨
            class QueueCallbackHandler(BaseCallbackHandler):
                def __init__(self, queue):
                    self.queue = queue
                    super().__init__()
                
                def on_llm_new_token(self, token: str, **kwargs) -> None:
                    self.queue.put(token)
            
            # åˆ›å»ºä¸€ä¸ªç”Ÿæˆå™¨å‡½æ•°ï¼Œç”¨äºæµå¼è¾“å‡º
            def token_generator():
                while True:
                    try:
                        token = message_queue.get(block=False)
                        yield token
                    except Empty:
                        if not thread.is_alive() and message_queue.empty():
                            break
                    time.sleep(0.01)
            
            # åœ¨å•ç‹¬çš„çº¿ç¨‹ä¸­è¿è¡Œç­–ç•¥åˆ¶å®š
            def run_strategy():
                try:
                    # å¦‚æœæ”¯æŒæ–‡ä»¶åˆ†æç»“æœä¸ºç©ºï¼Œæä¾›é»˜è®¤å€¼
                    if not support_analysis:
                        support_analysis = "æœªæä¾›æ”¯æŒæ–‡ä»¶åˆ†ææŠ¥å‘Š"
                    
                    result = self.strategy_chain(
                        {
                            "ps_draft": ps_draft,
                            "support_analysis": support_analysis,
                            "school_name": school_name,
                            "program_name": program_name
                        },
                        callbacks=[QueueCallbackHandler(message_queue)]
                    )
                    
                    message_queue.put("\n\nPSæ”¹å†™ç­–ç•¥æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
                    thread.result = result["ps_strategy_result"]
                    return result
                    
                except Exception as e:
                    message_queue.put(f"\n\né”™è¯¯: {str(e)}")
                    logger.error(f"PSç­–ç•¥åˆ¶å®šé”™è¯¯: {str(e)}")
                    thread.exception = e
                    raise e
            
            # å¯åŠ¨çº¿ç¨‹
            thread = Thread(target=run_strategy)
            thread.start()
            
            # ç”¨äºæµå¼è¾“å‡ºçš„å®¹å™¨
            output_container = st.empty()
            
            # æµå¼è¾“å‡º
            with output_container:
                full_response = st.write_stream(token_generator())
            
            # ç­‰å¾…çº¿ç¨‹å®Œæˆ
            thread.join()
            
            # æ¸…ç©ºåŸå®¹å™¨å¹¶ä½¿ç”¨markdowné‡æ–°æ¸²æŸ“å®Œæ•´å“åº”
            if hasattr(thread, "result"):
                output_container.empty()
                output_container.markdown(thread.result)
            
            # è·å–ç»“æœ
            if hasattr(thread, "exception") and thread.exception:
                raise thread.exception
            
            logger.info("PSç­–ç•¥åˆ¶å®šå®Œæˆ")
            
            return {
                "status": "success",
                "ps_strategy_result": thread.result if hasattr(thread, "result") else full_response
            }
                
        except Exception as e:
            logger.error(f"PSç­–ç•¥åˆ¶å®šé”™è¯¯: {str(e)}")
            return {
                "status": "error",
                "message": str(e)
            }

class ContentCreationAgent:
    def __init__(self, api_key: str, prompt_templates: PromptTemplates):
        self.prompt_templates = prompt_templates
            
        self.llm = ChatOpenAI(
            temperature=0.1,
            model=st.session_state.content_creation_model,  # ä½¿ç”¨session stateä¸­çš„æ¨¡å‹
            api_key=api_key,
            base_url="https://openrouter.ai/api/v1",
            streaming=True
        )
        
        self.setup_chains()
    
    def setup_chains(self):
        # åˆ›å»ºå†…å®¹åˆ›ä½œçš„Chain
        creation_prompt = ChatPromptTemplate.from_messages([
            ("system", f"{self.prompt_templates.get_template('content_creation_role')}\n\n"
                     f"ä»»åŠ¡:\n{self.prompt_templates.get_template('content_creation_task')}\n\n"
                     f"è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡º:\n{self.prompt_templates.get_template('content_creation_output')}"),
            ("human", "è¯·æ ¹æ®ä»¥ä¸‹èµ„æ–™åˆ›ä½œä¸ªäººé™ˆè¿°å†…å®¹ï¼š\n\nPSæ”¹å†™ç­–ç•¥æŠ¥å‘Šï¼š\n{ps_strategy}\n\nPSåˆç¨¿å†…å®¹ï¼š\n{ps_draft}\n\næ”¯æŒæ–‡ä»¶åˆ†ææŠ¥å‘Šï¼š\n{support_analysis}\n\nç›®æ ‡å­¦æ ¡å’Œä¸“ä¸šï¼š\nå­¦æ ¡ï¼š{school_name}\nä¸“ä¸šï¼š{program_name}")
        ])
        
        self.creation_chain = LLMChain(
            llm=self.llm,
            prompt=creation_prompt,
            output_key="content_creation_result",
            verbose=True
        )
    
    def create_content(self, ps_strategy: str, ps_draft: str, support_analysis: str, school_name: str, program_name: str) -> Dict[str, Any]:
        try:
            # åˆ›å»ºä¸€ä¸ªé˜Ÿåˆ—ç”¨äºæµå¼è¾“å‡º
            message_queue = Queue()
            
            # åˆ›å»ºè‡ªå®šä¹‰å›è°ƒå¤„ç†å™¨
            class QueueCallbackHandler(BaseCallbackHandler):
                def __init__(self, queue):
                    self.queue = queue
                    super().__init__()
                
                def on_llm_new_token(self, token: str, **kwargs) -> None:
                    self.queue.put(token)
            
            # åˆ›å»ºä¸€ä¸ªç”Ÿæˆå™¨å‡½æ•°ï¼Œç”¨äºæµå¼è¾“å‡º
            def token_generator():
                while True:
                    try:
                        token = message_queue.get(block=False)
                        yield token
                    except Empty:
                        if not thread.is_alive() and message_queue.empty():
                            break
                    time.sleep(0.01)
            
            # åœ¨å•ç‹¬çš„çº¿ç¨‹ä¸­è¿è¡Œå†…å®¹åˆ›ä½œ
            def run_creation():
                try:
                    # å¦‚æœæ”¯æŒæ–‡ä»¶åˆ†æç»“æœä¸ºç©ºï¼Œæä¾›é»˜è®¤å€¼
                    if not support_analysis:
                        support_analysis = "æœªæä¾›æ”¯æŒæ–‡ä»¶åˆ†ææŠ¥å‘Š"
                    
                    result = self.creation_chain(
                        {
                            "ps_strategy": ps_strategy,
                            "ps_draft": ps_draft,
                            "support_analysis": support_analysis,
                            "school_name": school_name,
                            "program_name": program_name
                        },
                        callbacks=[QueueCallbackHandler(message_queue)]
                    )
                    
                    message_queue.put("\n\nä¸ªäººé™ˆè¿°å†…å®¹åˆ›ä½œå®Œæˆï¼")
                    thread.result = result["content_creation_result"]
                    return result
                    
                except Exception as e:
                    message_queue.put(f"\n\né”™è¯¯: {str(e)}")
                    logger.error(f"å†…å®¹åˆ›ä½œé”™è¯¯: {str(e)}")
                    thread.exception = e
                    raise e
            
            # å¯åŠ¨çº¿ç¨‹
            thread = Thread(target=run_creation)
            thread.start()
            
            # ç”¨äºæµå¼è¾“å‡ºçš„å®¹å™¨
            output_container = st.empty()
            
            # æµå¼è¾“å‡º
            with output_container:
                full_response = st.write_stream(token_generator())
            
            # ç­‰å¾…çº¿ç¨‹å®Œæˆ
            thread.join()
            
            # æ¸…ç©ºåŸå®¹å™¨å¹¶ä½¿ç”¨markdowné‡æ–°æ¸²æŸ“å®Œæ•´å“åº”
            if hasattr(thread, "result"):
                output_container.empty()
                output_container.markdown(thread.result)
            
            # è·å–ç»“æœ
            if hasattr(thread, "exception") and thread.exception:
                raise thread.exception
            
            logger.info("å†…å®¹åˆ›ä½œå®Œæˆ")
            
            return {
                "status": "success",
                "content_creation_result": thread.result if hasattr(thread, "result") else full_response
            }
                
        except Exception as e:
            logger.error(f"å†…å®¹åˆ›ä½œé”™è¯¯: {str(e)}")
            return {
                "status": "error",
                "message": str(e)
            }

def render_status_indicator():
    """æ¸²æŸ“MCPè¿æ¥çŠ¶æ€æŒ‡ç¤ºå™¨"""
    st.sidebar.divider()
    
    # å±•ç¤ºMCPè¿æ¥çŠ¶æ€
    if MCP_AVAILABLE:
        st.sidebar.markdown("ğŸŸ¢ **MCPçŠ¶æ€: å·²è¿æ¥** (ä½¿ç”¨å®˜æ–¹å®ç°)")
    else:
        try:
            # æµ‹è¯•MCPå¯¼å…¥
            import mcp
            version = getattr(mcp, "__version__", "æœªçŸ¥")
            # æ·»åŠ è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
            if hasattr(st.session_state, 'mcp_error'):
                error_msg = st.session_state.mcp_error
                st.sidebar.markdown(f"ğŸ”Œ **MCPçŠ¶æ€: æœªè¿æ¥** (ä½¿ç”¨å¤‡ç”¨å®ç°)")
                with st.sidebar.expander("æŸ¥çœ‹è¿æ¥é”™è¯¯è¯¦æƒ…"):
                    st.error(f"MCPç‰ˆæœ¬: {version}\né”™è¯¯: {error_msg}")
            else:
                if "SMITHERY_API_KEY" not in st.secrets:
                    st.sidebar.markdown(f"ğŸ”Œ **MCPçŠ¶æ€: æœªè¿æ¥** (ä½¿ç”¨å¤‡ç”¨å®ç°)")
                    with st.sidebar.expander("æŸ¥çœ‹è¿æ¥é”™è¯¯è¯¦æƒ…"):
                        st.error("æœªé…ç½®Smithery APIå¯†é’¥")
                else:
                    st.sidebar.markdown(f"ğŸ”Œ **MCPçŠ¶æ€: æœªè¿æ¥** (ä½¿ç”¨å¤‡ç”¨å®ç°)")
                    with st.sidebar.expander("æŸ¥çœ‹è¿æ¥é”™è¯¯è¯¦æƒ…"):
                        st.error("æ— æ³•è¿æ¥åˆ°SmitheryæœåŠ¡å™¨ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–APIå¯†é’¥")
        except ImportError:
            st.sidebar.markdown("ğŸ”Œ **MCPçŠ¶æ€: æœªè¿æ¥** (ä½¿ç”¨å¤‡ç”¨å®ç°)")
            with st.sidebar.expander("æŸ¥çœ‹è¿æ¥é”™è¯¯è¯¦æƒ…"):
                st.error("æœªå®‰è£…MCPæ¨¡å—")
    
    st.sidebar.divider()

if __name__ == "__main__":
    main()